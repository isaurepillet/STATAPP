{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from postal.expand import expand_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DPE ADEME**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGEMENTS EXISTANTS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4537525"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/DPE/DPE_ADEME/dpe-v2-logements-existants.csv\",\n",
    "    sep=\",\",  # Séparateur CSV\n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False)\n",
    "\n",
    "df['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On filtre pour n'avoir que les données du département 44 en 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_réception_DPE'] = pd.to_datetime(df['Date_réception_DPE'], errors='coerce')\n",
    "dfv1 = df[df['Date_réception_DPE'].dt.year == 2022].copy()\n",
    "dfv2 = dfv1[dfv1['N°_département_(BAN)']=='44'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64490"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfv2['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction normalize renvoie des listes de différentes versions d'adresses possibles (ex Chateau-Thabut ; Chateau Thabut ; ChateauThabut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec cette version de la fonction on ne garde que la première composante de la liste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_address(address):\n",
    "    if pd.isna(address) or address.strip() == '':\n",
    "        return None  \n",
    "    try:\n",
    "        normalized = expand_address(address)  \n",
    "        return normalized[0] if normalized else None  # Ne garde que la première version\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec l'adresse '{address}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv2['Adresse_Normalisee'] = dfv2['Adresse_(BAN)'].apply(normalize_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGEMENTS NEUFS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537952"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/DPE/DPE_ADEME/dpe-v2-logements-neufs.csv\",\n",
    "    sep=\",\",  # Séparateur CSV\n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False)\n",
    "\n",
    "df2['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Date_réception_DPE'] = pd.to_datetime(df2['Date_réception_DPE'], errors='coerce')\n",
    "df2v1 = df2[df2['Date_réception_DPE'].dt.year == 2022].copy()\n",
    "df2v2 = df2v1[df2v1['N°_département_(BAN)']=='44'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11624"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2v2['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2v2['Adresse_Normalisee'] = df2v2['Adresse_(BAN)'].apply(normalize_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALEURS FONCIERES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vf = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/ValeursFoncieres/valeursfoncieres-2022.txt\",\n",
    "    sep=\"|\",  \n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No voie         float64\n",
      "Type de voie     object\n",
      "Voie             object\n",
      "Code postal     float64\n",
      "Commune          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(vf[['No voie', 'Type de voie', 'Voie', 'Code postal', 'Commune']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir explicitement toutes les colonnes en chaînes\n",
    "vf['Adresse'] = vf['No voie'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf['Type de voie'].fillna('').astype(str) + \" \" + \\\n",
    "                vf['Voie'].fillna('').astype(str) + \", \" + \\\n",
    "                vf['Code postal'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf['Commune'].fillna('').astype(str)\n",
    "\n",
    "vf['Adresse'] = vf['Adresse'].str.strip().replace(r'^\\s*$', None, regex=True)  # Supprime les adresses vides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf44 = vf[vf['Code postal'].notna()]\n",
    "vf44 = vf44[vf44['Code postal'].astype(str).str.startswith('44')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf44['Adresse'] = vf44['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf44['Adresse_Normalisee'] = vf44['Adresse'].apply(normalize_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99874\n"
     ]
    }
   ],
   "source": [
    "print(len(vf44['Adresse_Normalisee']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MATCHING AVEC PARSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(df):\n",
    "    adresse_counts = df['Adresse_Normalisee'].value_counts()\n",
    "    nb_adresses_uniques = (adresse_counts == 1).sum()\n",
    "    print(\"Nombre d'adresses uniques dans le fichier :\")\n",
    "    return nb_adresses_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'adresses uniques dans le fichier :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22972"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(dfv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'adresses uniques dans le fichier :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16910"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(vf44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'adresses dupliquées dans dfv2 (logements existants) : 7513\n",
      "Nombre d'adresses dupliquées dans df2v2 (logements neufs) : 707\n",
      "Nombre d'adresses dupliquées dans vf44 (valeurs foncières) : 20674\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre d'adresses dupliquées dans dfv2 (logements existants) : {dfv2 ['Adresse_Normalisee'].value_counts().ge(2).sum()}\")\n",
    "print(f\"Nombre d'adresses dupliquées dans df2v2 (logements neufs) : {df2v2 ['Adresse_Normalisee'].value_counts().ge(2).sum()}\")\n",
    "print(f\"Nombre d'adresses dupliquées dans vf44 (valeurs foncières) : {vf44 ['Adresse_Normalisee'].value_counts().ge(2).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAVAIL SUR LES DOUBLONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOUBLONS DANS DOC LOGEMENTS EXISTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage d'adresses en doublon : 11.65%\n",
      "Liste des adresses en doublon :\n",
      "['1 rue de cahors 44800 saint-herblain', '5 avenue robert chasteland 44700 orvault', '32 route de la joneliere 44300 nantes', '24 rue blaise pascal 44300 nantes', 'route de saint joseph 44300 nantes', '4 avenue des jades 44300 nantes', 'rue de la coran 44400 reze', '8 place francois ii 44200 nantes', '129 rue de la mirette 44400 reze', '5 rue de biarritz 44200 nantes']\n"
     ]
    }
   ],
   "source": [
    "def calculate_duplicate_percentage(df, address_column):\n",
    "    \"\"\"\n",
    "    On calcule le pourcentage d'adresses en doublon + on en fait une liste\n",
    "    \"\"\"\n",
    "    total_count = len(df)\n",
    "    duplicate_counts = df[address_column].value_counts()\n",
    "    duplicate_addresses = duplicate_counts[duplicate_counts > 1].index.tolist()\n",
    "    duplicate_count = len(duplicate_addresses)\n",
    "    duplicate_percentage = (duplicate_count / total_count) * 100 if total_count > 0 else 0\n",
    "    \n",
    "    return duplicate_percentage, duplicate_addresses\n",
    "\n",
    "# On applique la fonction aux logements existants\n",
    "duplicate_percentage, duplicate_addresses = calculate_duplicate_percentage(dfv2, 'Adresse_Normalisee')\n",
    "\n",
    "print(f\"Pourcentage d'adresses en doublon : {duplicate_percentage:.2f}%\")\n",
    "\n",
    "liste = duplicate_addresses\n",
    "print(\"Liste des adresses en doublon :\")\n",
    "print(liste[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOUBLONS DANS VF44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage d'adresses en doublon : 20.70%\n",
      "Liste des adresses en doublon :\n",
      "['1 rue de cahors 44800 saint-herblain', '5 avenue robert chasteland 44700 orvault', '32 route de la joneliere 44300 nantes', '24 rue blaise pascal 44300 nantes', 'route de saint joseph 44300 nantes', '4 avenue des jades 44300 nantes', 'rue de la coran 44400 reze', '8 place francois ii 44200 nantes', '129 rue de la mirette 44400 reze', '5 rue de biarritz 44200 nantes']\n"
     ]
    }
   ],
   "source": [
    "def calculate_duplicate_percentage(df, address_column):\n",
    "    \"\"\"\n",
    "    On calcule le pourcentage d'adresses en doublon + on en fait une liste\n",
    "    \"\"\"\n",
    "    total_count = len(df)\n",
    "    duplicate_counts = df[address_column].value_counts()\n",
    "    duplicate_addresses2 = duplicate_counts[duplicate_counts > 1].index.tolist()\n",
    "    duplicate_count = len(duplicate_addresses2)\n",
    "    duplicate_percentage = (duplicate_count / total_count) * 100 if total_count > 0 else 0\n",
    "    \n",
    "    return duplicate_percentage, duplicate_addresses\n",
    "\n",
    "# On applique la fonction aux logements existants\n",
    "duplicate_percentage, duplicate_addresses2 = calculate_duplicate_percentage(vf44, 'Adresse_Normalisee')\n",
    "\n",
    "print(f\"Pourcentage d'adresses en doublon : {duplicate_percentage:.2f}%\")\n",
    "\n",
    "liste = duplicate_addresses2\n",
    "print(\"Liste des adresses en doublon :\")\n",
    "print(liste[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATION DUNE LISTE AVEC LES ADRESSES UNIQUES ET EN DOUBLON POUR COMPTER NOMBRE DE MATCHING A EFFECTUER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des adresses uniques + adresses en doublon (mais une seule fois) :\n",
      "['7 rue de courtigon 44210 pornic', '46 rue de la bourdonnais 44100 nantes', '35 rue de la chicotiere 44800 saint-herblain', '23 avenue centre henri de cosse brissac 44540 vallons-de-lerdre', '51 rue du grand puits 44450 divatte-sur-loire', '10 rue georges clemenceau 44340 bouguenais', '48ter rue des primeveres 44220 coueron', '29 avenue des noes 44380 pornichet', '18 square des tilleuls 44522 mesanger', '23 rue herve bazin 44130 blain']\n",
      "30485\n"
     ]
    }
   ],
   "source": [
    "adresse_counts = dfv2['Adresse_Normalisee'].value_counts()\n",
    "\n",
    "# Séparer les adresses uniques et celles en doublon (qu'on ne garde qu'une seule fois)\n",
    "adresses_uniques = adresse_counts[adresse_counts == 1].index.tolist()\n",
    "adresses_doublons = adresse_counts[adresse_counts > 1].index.tolist()\n",
    "\n",
    "# Fusionner les deux listes\n",
    "adresses_finales = adresses_uniques + adresses_doublons\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"Liste des adresses uniques + adresses en doublon (mais une seule fois) :\")\n",
    "print(adresses_finales[:10])\n",
    "print(len(adresses_finales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille finale de la liste : 37584\n",
      "Liste des adresses uniques + adresses en doublon (mais une seule fois) :\n",
      "['l ouche du puits fresnay 44580 villeneuve-en-retz', 'le landier du ruaud 44410 asserac', '17 rue du puy civaux 44580 villeneuve-en-retz', 'les malabris 44130 notre dame des landes', '5362 le perron 44160 besne', '83 l annerie 44190 getigne', 'les landes de la piolais 44160 crossac', '3 rue du taillis 44140 montbert', '2 impasse des papillons 44450 saint-julien-de-concelles', '1 rue des chaloires 44760 la bernerie enceinte retz']\n"
     ]
    }
   ],
   "source": [
    "adresse_counts = vf44['Adresse_Normalisee'].dropna().value_counts()\n",
    "\n",
    "\n",
    "adresses_uniques = list(adresse_counts[adresse_counts == 1].index)\n",
    "adresses_doublons = list(adresse_counts[adresse_counts > 1].index)\n",
    "\n",
    "adresses_finales2 = adresses_uniques + adresses_doublons\n",
    "\n",
    "print(f\"Taille finale de la liste : {len(adresses_finales2)}\")\n",
    "print(\"Liste des adresses uniques + adresses en doublon (mais une seule fois) :\")\n",
    "print(adresses_finales2[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'adresses en commun : 7120\n",
      "Exemples d'adresses en commun : ['134 route des frechets 44600 saint-nazaire', '9 rue scribe 44000 nantes', '6 boulevard francois blancho 44200 nantes', '11 rue albert vincon 44570 trignac', '32 rue eugene guillevic 44150 ancenis-saint-gereon', 'la champeliere 44540 vallons-de-lerdre', '35 rue saint benoit 44290 masserac', '31 rue des grands patis 44300 nantes', '32 route de pont caffino 44120 vertou', '8 rue du 8 mai 44130 blain']\n"
     ]
    }
   ],
   "source": [
    "# Conversion des listes en ensemble\n",
    "set_adresses_finales = set(adresses_finales)\n",
    "set_adresses_finales2 = set(adresses_finales2)\n",
    "\n",
    "# Adresses en commun\n",
    "adresses_communes = set_adresses_finales.intersection(set_adresses_finales2)\n",
    "\n",
    "print(f\"Nombre d'adresses en commun : {len(adresses_communes)}\")\n",
    "\n",
    "# Exemple d'adresses en commun\n",
    "print(\"Exemples d'adresses en commun :\", list(adresses_communes)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEILLEURE VISION DES DOUBLONS EN CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention à ne pas push sur git le fichier csv généré (il est trop lourd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/ymcp1z4s7n77n5bhz3q_hgqc0000gn/T/ipykernel_3393/2984065862.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_common_dupes = pd.concat([vf44_common, dfv2_common], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier CSV exporté : adresses_doublon_communes.csv\n"
     ]
    }
   ],
   "source": [
    "def export_duplicate_addresses(dfv2, vf44, output_file):\n",
    "    # Identifier les adresses en doublon dans vf44\n",
    "    vf44_dupes = vf44[vf44['Adresse_Normalisee'].duplicated(keep=False)]\n",
    "    \n",
    "    # Identifier les adresses en doublon dans dfv2\n",
    "    dfv2_dupes = dfv2[dfv2['Adresse_Normalisee'].duplicated(keep=False)]\n",
    "    \n",
    "    # Trouver les adresses en commun entre les deux jeux de données\n",
    "    common_addresses = set(vf44_dupes['Adresse_Normalisee']).intersection(set(dfv2_dupes['Adresse_Normalisee']))\n",
    "    \n",
    "    # Filtrer les données pour ne conserver que celles ayant une adresse en commun\n",
    "    vf44_common = vf44[vf44['Adresse_Normalisee'].isin(common_addresses)].copy()\n",
    "    dfv2_common = dfv2[dfv2['Adresse_Normalisee'].isin(common_addresses)].copy()\n",
    "    \n",
    "    # Ajouter une colonne Source pour identifier l'origine des données\n",
    "    vf44_common['Source'] = 'vf44'\n",
    "    dfv2_common['Source'] = 'dfv2'\n",
    "    \n",
    "    # Harmoniser les colonnes des deux dataframes\n",
    "    all_columns = list(set(dfv2_common.columns).union(set(vf44_common.columns)))\n",
    "    vf44_common = vf44_common.reindex(columns=all_columns)\n",
    "    dfv2_common = dfv2_common.reindex(columns=all_columns)\n",
    "    \n",
    "    # Concaténer les deux jeux de données sans perte d'information\n",
    "    all_common_dupes = pd.concat([vf44_common, dfv2_common], ignore_index=True)\n",
    "    \n",
    "    # Trier par adresse normalisée pour regrouper les doublons\n",
    "    all_common_dupes = all_common_dupes.sort_values(by=['Adresse_Normalisee'])\n",
    "    \n",
    "    # Exporter en CSV\n",
    "    all_common_dupes.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"Fichier CSV exporté : {output_file}\")\n",
    "\n",
    "export_duplicate_addresses(dfv2, vf44, \"adresses_doublon_communes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque un problème avec les dépendances qui ont les mêmes infos que les appartements dans lesquels elles sont situées. On veut voir quelle quantité elles représentent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes avec le type de local 'Dépendance' dans vf44 : 26009\n",
      "99874\n"
     ]
    }
   ],
   "source": [
    "# Filtre\n",
    "dependance_count = vf44[vf44['Type local'] == 'Dépendance'].shape[0]\n",
    "\n",
    "print(f\"Nombre de lignes avec le type de local 'Dépendance' dans vf44 : {dependance_count}\")\n",
    "# Nombre total de lignes\n",
    "print(len(vf44['Type local']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
