{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from postal.expand import expand_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DPE ADEME**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGEMENTS EXISTANTS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4537525"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/DPE/DPE_ADEME/dpe-v2-logements-existants.csv\",\n",
    "    sep=\",\",  # Séparateur CSV\n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False)\n",
    "\n",
    "df['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On filtre pour n'avoir que les données du département 44 en 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_réception_DPE'] = pd.to_datetime(df['Date_réception_DPE'], errors='coerce')\n",
    "dfv1 = df[df['Date_réception_DPE'].dt.year == 2022].copy()\n",
    "dfv2 = dfv1[dfv1['N°_département_(BAN)']=='44'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64490"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfv2['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction normalize renvoie des listes de différentes versions d'adresses possibles (ex Chateau-Thabut ; Chateau Thabut ; ChateauThabut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec cette version de la fonction on ne garde que la première composante de la liste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_address(address):\n",
    "    if pd.isna(address) or address.strip() == '':\n",
    "        return None  \n",
    "    try:\n",
    "        normalized = expand_address(address)  \n",
    "        return normalized[0] if normalized else None  # Ne garde que la première version\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec l'adresse '{address}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv2['Adresse_Normalisee'] = dfv2['Adresse_(BAN)'].apply(normalize_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGEMENTS NEUFS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537952"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/DPE/DPE_ADEME/dpe-v2-logements-neufs.csv\",\n",
    "    sep=\",\",  # Séparateur CSV\n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False)\n",
    "\n",
    "df2['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Date_réception_DPE'] = pd.to_datetime(df2['Date_réception_DPE'], errors='coerce')\n",
    "df2v1 = df2[df2['Date_réception_DPE'].dt.year == 2022].copy()\n",
    "df2v2 = df2v1[df2v1['N°_département_(BAN)']=='44'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11624"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2v2['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2v2['Adresse_Normalisee'] = df2v2['Adresse_(BAN)'].apply(normalize_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALEURS FONCIERES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vf = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/ValeursFoncieres/valeursfoncieres-2022.txt\",\n",
    "    sep=\"|\",  \n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No voie         float64\n",
      "Type de voie     object\n",
      "Voie             object\n",
      "Code postal     float64\n",
      "Commune          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(vf[['No voie', 'Type de voie', 'Voie', 'Code postal', 'Commune']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir explicitement toutes les colonnes en chaînes\n",
    "vf['Adresse'] = vf['No voie'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf['Type de voie'].fillna('').astype(str) + \" \" + \\\n",
    "                vf['Voie'].fillna('').astype(str) + \", \" + \\\n",
    "                vf['Code postal'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf['Commune'].fillna('').astype(str)\n",
    "\n",
    "vf['Adresse'] = vf['Adresse'].str.strip().replace(r'^\\s*$', None, regex=True)  # Supprime les adresses vides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf44 = vf[vf['Code postal'].notna()]\n",
    "vf44 = vf44[vf44['Code postal'].astype(str).str.startswith('44')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf44['Adresse'] = vf44['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf44['Adresse_Normalisee'] = vf44['Adresse'].apply(normalize_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99874\n"
     ]
    }
   ],
   "source": [
    "print(len(vf44['Adresse_Normalisee']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MATCHING ETUDE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(df):\n",
    "    adresse_counts = df['Adresse_Normalisee'].value_counts()\n",
    "    nb_adresses_uniques = (adresse_counts == 1).sum()\n",
    "    return nb_adresses_uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22972"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(dfv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16910"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique(vf44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'adresses dupliquées dans dfv2 (logements existants) : 7513\n",
      "Nombre d'adresses dupliquées dans df2v2 (logements neufs) : 707\n",
      "Nombre d'adresses dupliquées dans vf44 (valeurs foncières) : 20674\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre d'adresses dupliquées dans dfv2 (logements existants) : {dfv2 ['Adresse_Normalisee'].value_counts().ge(2).sum()}\")\n",
    "print(f\"Nombre d'adresses dupliquées dans df2v2 (logements neufs) : {df2v2 ['Adresse_Normalisee'].value_counts().ge(2).sum()}\")\n",
    "print(f\"Nombre d'adresses dupliquées dans vf44 (valeurs foncières) : {vf44 ['Adresse_Normalisee'].value_counts().ge(2).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAVAIL SUR LES DOUBLONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOUBLONS DANS DOC LOGEMENTS EXISTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_duplicate_percentage(df, address_column):\n",
    "    \"\"\"\n",
    "    On calcule le pourcentage d'adresses en doublon + on en fait une liste\n",
    "    \"\"\"\n",
    "    total_count = len(df)\n",
    "    duplicate_counts = df[address_column].value_counts()\n",
    "    duplicate_addresses = duplicate_counts[duplicate_counts > 1].index.tolist()\n",
    "    duplicate_count = len(duplicate_addresses)\n",
    "    duplicate_percentage = (duplicate_count / total_count) * 100 if total_count > 0 else 0\n",
    "    \n",
    "    return duplicate_percentage, duplicate_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage d'adresses en doublon : 11.65%\n",
      "Liste des adresses en doublon :\n",
      "['1 rue de cahors 44800 saint-herblain', '5 avenue robert chasteland 44700 orvault', '32 route de la joneliere 44300 nantes', '24 rue blaise pascal 44300 nantes', 'route de saint joseph 44300 nantes', '4 avenue des jades 44300 nantes', 'rue de la coran 44400 reze', '8 place francois ii 44200 nantes', '129 rue de la mirette 44400 reze', '5 rue de biarritz 44200 nantes']\n",
      "7513\n"
     ]
    }
   ],
   "source": [
    "# On applique la fonction aux logements existants de dfv2\n",
    "duplicate_percentage, duplicate_addresses = calculate_duplicate_percentage(dfv2, 'Adresse_Normalisee')\n",
    "print(f\"Pourcentage d'adresses en doublon : {duplicate_percentage:.2f}%\")\n",
    "print(\"Liste des adresses en doublon :\")\n",
    "print(duplicate_addresses[:10])\n",
    "print(len(duplicate_addresses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOUBLONS DANS VF44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage d'adresses en doublon : 20.70%\n",
      "Liste des adresses en doublon :\n",
      "['13 rue de saint servan 44800 st-herblain', 'rue de la jaunaie 44230 saint sebastien sur loire', 'rue joshua slocum 44210 pornic', '51 rue hector berlioz 44300 nantes', 'zone industrielle de brais 44600 saint-nazaire', '43 boulevard des batignolles 44300 nantes', '66 rue de nantes 44830 bouaye', 'favet 44650 corcoue-sur-logne', '95 avenue de la patouillerie 44700 orvault', 'le butay 44140 montbert']\n",
      "20674\n"
     ]
    }
   ],
   "source": [
    "# On applique la fonction aux logements existants de vf44\n",
    "duplicate_percentage2, duplicate_addresses2 = calculate_duplicate_percentage(vf44, 'Adresse_Normalisee')\n",
    "print(f\"Pourcentage d'adresses en doublon : {duplicate_percentage2:.2f}%\")\n",
    "liste2 = duplicate_addresses2\n",
    "print(\"Liste des adresses en doublon :\")\n",
    "print(liste2[:10])\n",
    "print(len(liste2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ON CHERCHE LES ADRESSES A MATCH PARMI CES DOUBLONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1881\n"
     ]
    }
   ],
   "source": [
    "set_adresses = set(duplicate_addresses)\n",
    "set_adresses2 = set(duplicate_addresses2)\n",
    "# Adresses en commun\n",
    "adresses_match = set_adresses.intersection(set_adresses2)\n",
    "print(len(adresses_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc sur toutes les adresses en doublons il y aurait seulement 1881 potentiellement à match. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule la perte potentielle si on venait à enlever tous les doublons et ne garder que les adresses uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164364\n",
      "39882\n",
      "24.2644374680587\n"
     ]
    }
   ],
   "source": [
    "longueur = len(vf44)+len(dfv2)\n",
    "print(longueur)\n",
    "match_adresses_uniques = unique(dfv2)+unique(vf44)\n",
    "print(match_adresses_uniques)\n",
    "print(match_adresses_uniques*100/longueur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On perdrait donc environ 24% de l'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATION DUNE LISTE AVEC LES ADRESSES UNIQUES ET EN DOUBLON POUR COMPTER NOMBRE DE MATCHING A EFFECTUER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste des adresses uniques + adresses en doublon (mais une seule fois) :\n",
      "['7 rue de courtigon 44210 pornic', '46 rue de la bourdonnais 44100 nantes', '35 rue de la chicotiere 44800 saint-herblain', '23 avenue centre henri de cosse brissac 44540 vallons-de-lerdre', '51 rue du grand puits 44450 divatte-sur-loire', '10 rue georges clemenceau 44340 bouguenais', '48ter rue des primeveres 44220 coueron', '29 avenue des noes 44380 pornichet', '18 square des tilleuls 44522 mesanger', '23 rue herve bazin 44130 blain']\n",
      "30485\n"
     ]
    }
   ],
   "source": [
    "adresse_counts = dfv2['Adresse_Normalisee'].value_counts()\n",
    "\n",
    "# Séparer les adresses uniques et celles en doublon (qu'on ne garde qu'une seule fois)\n",
    "adresses_uniques = adresse_counts[adresse_counts == 1].index.tolist()\n",
    "adresses_doublons = adresse_counts[adresse_counts > 1].index.tolist()\n",
    "\n",
    "# Fusionner les deux listes\n",
    "adresses_finales = adresses_uniques + adresses_doublons\n",
    "\n",
    "# Affichage du résultat\n",
    "print(\"Liste des adresses uniques + adresses en doublon (mais une seule fois) :\")\n",
    "print(adresses_finales[:10])\n",
    "print(len(adresses_finales))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille finale de la liste : 37584\n",
      "Liste des adresses uniques + adresses en doublon (mais une seule fois) :\n",
      "['l ouche du puits fresnay 44580 villeneuve-en-retz', 'le landier du ruaud 44410 asserac', '17 rue du puy civaux 44580 villeneuve-en-retz', 'les malabris 44130 notre dame des landes', '5362 le perron 44160 besne', '83 l annerie 44190 getigne', 'les landes de la piolais 44160 crossac', '3 rue du taillis 44140 montbert', '2 impasse des papillons 44450 saint-julien-de-concelles', '1 rue des chaloires 44760 la bernerie enceinte retz']\n"
     ]
    }
   ],
   "source": [
    "adresse_counts = vf44['Adresse_Normalisee'].dropna().value_counts()\n",
    "\n",
    "\n",
    "adresses_uniques = list(adresse_counts[adresse_counts == 1].index)\n",
    "adresses_doublons = list(adresse_counts[adresse_counts > 1].index)\n",
    "\n",
    "adresses_finales2 = adresses_uniques + adresses_doublons\n",
    "\n",
    "print(f\"Taille finale de la liste : {len(adresses_finales2)}\")\n",
    "print(\"Liste des adresses uniques + adresses en doublon (mais une seule fois) :\")\n",
    "print(adresses_finales2[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'adresses en commun : 7120\n",
      "Exemples d'adresses en commun : ['28 boulevard jules verne 44300 nantes', 'rue de montrelais 44370 loireauxence', '4 la lande mulon 44320 chauve', '4 allee de la piece des landes 44830 bouaye', '4 rue de la valee du havre 44521 couffe', '169 boulevard jules verne 44300 nantes', '15 rue faraday 44700 orvault', '5 avenue manet 44470 carquefou', '1 rue neuve 44420 piriac-sur-mer', '33 rue de la fontaine aux bretons 44210 pornic']\n"
     ]
    }
   ],
   "source": [
    "# Conversion des listes en ensemble\n",
    "set_adresses_finales = set(adresses_finales)\n",
    "set_adresses_finales2 = set(adresses_finales2)\n",
    "\n",
    "# Adresses en commun\n",
    "adresses_communes = set_adresses_finales.intersection(set_adresses_finales2)\n",
    "\n",
    "print(f\"Nombre d'adresses en commun : {len(adresses_communes)}\")\n",
    "\n",
    "# Exemple d'adresses en commun\n",
    "print(\"Exemples d'adresses en commun :\", list(adresses_communes)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEILLEURE VISION DES DOUBLONS EN CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention à ne pas push sur git le fichier csv généré (il est trop lourd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/ymcp1z4s7n77n5bhz3q_hgqc0000gn/T/ipykernel_3393/2984065862.py:25: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_common_dupes = pd.concat([vf44_common, dfv2_common], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier CSV exporté : adresses_doublon_communes.csv\n"
     ]
    }
   ],
   "source": [
    "def export_duplicate_addresses(dfv2, vf44, output_file):\n",
    "    # Identifier les adresses en doublon dans vf44\n",
    "    vf44_dupes = vf44[vf44['Adresse_Normalisee'].duplicated(keep=False)]\n",
    "    \n",
    "    # Identifier les adresses en doublon dans dfv2\n",
    "    dfv2_dupes = dfv2[dfv2['Adresse_Normalisee'].duplicated(keep=False)]\n",
    "    \n",
    "    # Trouver les adresses en commun entre les deux jeux de données\n",
    "    common_addresses = set(vf44_dupes['Adresse_Normalisee']).intersection(set(dfv2_dupes['Adresse_Normalisee']))\n",
    "    \n",
    "    # Filtrer les données pour ne conserver que celles ayant une adresse en commun\n",
    "    vf44_common = vf44[vf44['Adresse_Normalisee'].isin(common_addresses)].copy()\n",
    "    dfv2_common = dfv2[dfv2['Adresse_Normalisee'].isin(common_addresses)].copy()\n",
    "    \n",
    "    # Ajouter une colonne Source pour identifier l'origine des données\n",
    "    vf44_common['Source'] = 'vf44'\n",
    "    dfv2_common['Source'] = 'dfv2'\n",
    "    \n",
    "    # Harmoniser les colonnes des deux dataframes\n",
    "    all_columns = list(set(dfv2_common.columns).union(set(vf44_common.columns)))\n",
    "    vf44_common = vf44_common.reindex(columns=all_columns)\n",
    "    dfv2_common = dfv2_common.reindex(columns=all_columns)\n",
    "    \n",
    "    # Concaténer les deux jeux de données sans perte d'information\n",
    "    all_common_dupes = pd.concat([vf44_common, dfv2_common], ignore_index=True)\n",
    "    \n",
    "    # Trier par adresse normalisée pour regrouper les doublons\n",
    "    all_common_dupes = all_common_dupes.sort_values(by=['Adresse_Normalisee'])\n",
    "    \n",
    "    # Exporter en CSV\n",
    "    all_common_dupes.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"Fichier CSV exporté : {output_file}\")\n",
    "\n",
    "export_duplicate_addresses(dfv2, vf44, \"adresses_doublon_communes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque un problème avec les dépendances qui ont les mêmes infos que les appartements dans lesquels elles sont situées. On veut voir quelle quantité elles représentent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes avec le type de local 'Dépendance' dans vf44 : 26009\n",
      "99874\n"
     ]
    }
   ],
   "source": [
    "# Filtre\n",
    "dependance_count = vf44[vf44['Type local'] == 'Dépendance'].shape[0]\n",
    "\n",
    "print(f\"Nombre de lignes avec le type de local 'Dépendance' dans vf44 : {dependance_count}\")\n",
    "# Nombre total de lignes\n",
    "print(len(vf44['Type local']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREMIER TEST MATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date_réception_DPE', 'Date_établissement_DPE', 'Modèle_DPE',\n",
      "       'Date_fin_validité_DPE', 'Version_DPE', 'Méthode_application_DPE',\n",
      "       'Etiquette_DPE', 'Etiquette_GES', 'Année_construction', 'Type_bâtiment',\n",
      "       'Période_construction', 'Surface_habitable_logement', 'Adresse_brute',\n",
      "       'Nom__commune_(BAN)', 'Code_INSEE_(BAN)', 'N°_voie_(BAN)',\n",
      "       'Identifiant__BAN', 'Adresse_(BAN)', 'Code_postal_(BAN)', 'Score_BAN',\n",
      "       'Nom__rue_(BAN)', 'Coordonnée_cartographique_X_(BAN)',\n",
      "       'Coordonnée_cartographique_Y_(BAN)', 'Code_postal_(brut)',\n",
      "       'N°_étage_appartement', 'Nom_résidence', 'Cage_d'escalier',\n",
      "       'Complément_d'adresse_logement', 'Statut_géocodage',\n",
      "       'Nom__commune_(Brut)', 'N°_département_(BAN)', 'N°_région_(BAN)',\n",
      "       'Complément_d'adresse_bâtiment', 'Adresse_Normalisee'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dfv2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Identifiant de document', 'Reference document', '1 Articles CGI',\n",
      "       '2 Articles CGI', '3 Articles CGI', '4 Articles CGI', '5 Articles CGI',\n",
      "       'No disposition', 'Date mutation', 'Nature mutation', 'Valeur fonciere',\n",
      "       'No voie', 'B/T/Q', 'Type de voie', 'Code voie', 'Voie', 'Code postal',\n",
      "       'Commune', 'Code departement', 'Code commune', 'Prefixe de section',\n",
      "       'Section', 'No plan', 'No Volume', '1er lot',\n",
      "       'Surface Carrez du 1er lot', '2eme lot', 'Surface Carrez du 2eme lot',\n",
      "       '3eme lot', 'Surface Carrez du 3eme lot', '4eme lot',\n",
      "       'Surface Carrez du 4eme lot', '5eme lot', 'Surface Carrez du 5eme lot',\n",
      "       'Nombre de lots', 'Code type local', 'Type local', 'Identifiant local',\n",
      "       'Surface reelle bati', 'Nombre pieces principales', 'Nature culture',\n",
      "       'Nature culture speciale', 'Surface terrain', 'Adresse',\n",
      "       'Adresse_Normalisee'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(vf44.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code prend 2min environ à tourner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50675\n",
      "78240\n"
     ]
    }
   ],
   "source": [
    "def test_match(vf44,dfv2):\n",
    "    adresse_counts = vf44['Adresse_Normalisee'].dropna().value_counts()\n",
    "    unique1 = list(adresse_counts[adresse_counts == 1].index)\n",
    "    doublons1 = list(adresse_counts[adresse_counts > 1].index)\n",
    "    final = unique1 + doublons1\n",
    "    set_final = set(final)\n",
    "\n",
    "    adresse_counts2 = dfv2['Adresse_Normalisee'].dropna().value_counts()\n",
    "    unique2 = list(adresse_counts2[adresse_counts2 == 1].index)\n",
    "    doublons2 = list(adresse_counts2[adresse_counts2 > 1].index)\n",
    "    final2 = unique2 + doublons2\n",
    "    set_final2 = set(final2)\n",
    "\n",
    "    commun = set_final.intersection(set_final2)\n",
    "\n",
    "    vf44['Surface Carrez du 1er lot'] = pd.to_numeric(\n",
    "        vf44['Surface Carrez du 1er lot'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "    )\n",
    "    dfv2['Surface_habitable_logement'] = pd.to_numeric(\n",
    "        dfv2['Surface_habitable_logement'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "    )\n",
    "\n",
    "    merged = []\n",
    "\n",
    "    for adresse in commun:\n",
    "        dfv2sub = dfv2[dfv2['Adresse_Normalisee'] == adresse]\n",
    "        vf44sub = vf44[vf44['Adresse_Normalisee'] == adresse]\n",
    "\n",
    "        if len(dfv2sub)==1 and len(vf44sub)==1:\n",
    "            merged.append({**dfv2sub.iloc[0].to_dict(), **vf44sub.iloc[0].to_dict()})\n",
    "        else :\n",
    "             # Boucle sur les éléments de dfv2sub\n",
    "            for _, row2 in dfv2sub.iterrows():\n",
    "                matched = False\n",
    "                for _, row1 in vf44sub.iterrows():\n",
    "                    surface1 = row1['Surface Carrez du 1er lot']\n",
    "                    surface2 = row2['Surface_habitable_logement']\n",
    "                    \n",
    "                    # Vérification de l'écart de surface\n",
    "                    if abs(surface1 - surface2) / max(surface1, surface2) < 0.05:\n",
    "                        merged.append({**row2.to_dict(), **row1.to_dict()})\n",
    "                        matched = True\n",
    "                        break\n",
    "                \n",
    "                if not matched:\n",
    "                    merged.append(row2.to_dict())\n",
    "            \n",
    "            # Ajouter les éléments restants de vf44sub s'ils ne sont pas associés\n",
    "            for _, row1 in vf44sub.iterrows():\n",
    "                if not any(row1['Adresse_Normalisee'] == m['Adresse_Normalisee'] for m in merged):\n",
    "                    merged.append(row1.to_dict())\n",
    "        \n",
    "    dfv2_uniques = dfv2[~dfv2['Adresse_Normalisee'].isin(commun)]\n",
    "    print(len(dfv2_uniques))\n",
    "    vf44_uniques = vf44[~vf44['Adresse_Normalisee'].isin(commun)]\n",
    "    print(len(vf44_uniques))\n",
    "\n",
    "    df = pd.DataFrame(merged)\n",
    "    df = pd.concat([df, dfv2_uniques, vf44_uniques], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "test = test_match(vf44,dfv2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142730\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64490\n",
      "99874\n"
     ]
    }
   ],
   "source": [
    "print(len(dfv2))\n",
    "print(len(vf44))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
