{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from helpers2 import S3Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from postal.expand import expand_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "s3 = S3Connection(bucket_name=\"clichere/diffusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_logements_existants = \"DPE/DPE_ADEME/dpe-v2-logements-existants.csv\"\n",
    "df = s3.read_csv_from_s3(path_logements_existants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_vf_2022 = \"valeursfoncieres/vf_2022.csv\"\n",
    "vf2022 = s3.read_csv_from_s3(path_vf_2022)\n",
    "\n",
    "path_vf_2021 = \"valeursfoncieres/vf_2021.csv\"\n",
    "vf2021 = s3.read_csv_from_s3(path_vf_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FONCTIONS UTILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux fonctions suivantes permettent de normaliser les adresses présentes dans les deux bases de données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_address(address):\n",
    "    if pd.isna(address) or address.strip() == '':\n",
    "        return None  \n",
    "    try:\n",
    "        normalized = expand_address(address)  \n",
    "        return normalized[0] if normalized else None  # Ne garde que la première version de la normalisation\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec l'adresse '{address}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction est différente de la précédente car le problème de l'arrondissement après Paris ne se trouvait que dans la base de données vf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_vf_address(address, code_postal):\n",
    "    \"\"\" Normalise l'adresse et supprime l'arrondissement après 'PARIS' uniquement si le département est 75. \"\"\"\n",
    "    normalized_address = normalize_address(address)  \n",
    "\n",
    "    if pd.notna(normalized_address) and str(code_postal).startswith(\"75\"):\n",
    "        # Supprime le numéro après \"PARIS\" uniquement pour le département 75\n",
    "        normalized_address = re.sub(r'(paris) \\d{2}$', r'\\1', normalized_address, flags=re.IGNORECASE)\n",
    "    \n",
    "    return normalized_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant permet de relier les deux bases de données à partir des adresses normalisées en établissant un seuil d'écart de 5% entre les surfaces de chaque base (surface habitable / surface loi carrez)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match2(vf, df):\n",
    "    merged = []\n",
    "\n",
    "\n",
    "    #boucle par département\n",
    "    for department in df['N°_département_(BAN)'].unique():  \n",
    "        print(f\"Traitement du département : {department}\")\n",
    "        \n",
    "        #filtre\n",
    "        vf_dept = vf[vf['Code departement']==department].copy()\n",
    "        df_dept = df[df['N°_département_(BAN)']==department].copy()\n",
    "\n",
    "        #normalisation adresses\n",
    "        vf_dept['Adresse'] = vf_dept['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "        vf_dept['Adresse_Normalisee'] = vf_dept.apply(lambda row: normalize_vf_address(row['Adresse'], row['Code departement']), axis=1)\n",
    "        df_dept['Adresse_Normalisee'] = df_dept['Adresse_(BAN)'].apply(normalize_address)\n",
    "\n",
    "        #On distingue les adresses uniques et les adresses en doublons pour avoir deux catégories d'adresses et trouver celles communes aux deux bases\n",
    "        adresse_counts = vf_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique1 = list(adresse_counts[adresse_counts == 1].index)\n",
    "        doublons1 = list(adresse_counts[adresse_counts > 1].index)\n",
    "        final = unique1 + doublons1\n",
    "        set_final = set(final)\n",
    "\n",
    "        adresse_counts2 = df_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique2 = list(adresse_counts2[adresse_counts2 == 1].index)\n",
    "        doublons2 = list(adresse_counts2[adresse_counts2 > 1].index)\n",
    "        final2 = unique2 + doublons2\n",
    "        set_final2 = set(final2)\n",
    "\n",
    "        # On regarde les adresses communes\n",
    "        commun = set_final.intersection(set_final2)\n",
    "\n",
    "        vf_dept['Surface Carrez du 1er lot'] = pd.to_numeric(\n",
    "            vf_dept['Surface Carrez du 1er lot'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "        df_dept['Surface_habitable_logement'] = pd.to_numeric(\n",
    "            df_dept['Surface_habitable_logement'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "\n",
    "        for adresse in commun:\n",
    "            # On crée des sous dataframe contenant les lignes avec les mêmes adresses\n",
    "            dfsub = df_dept[df_dept['Adresse_Normalisee'] == adresse]\n",
    "            vfsub = vf_dept[vf_dept['Adresse_Normalisee'] == adresse]\n",
    "\n",
    "            # Boucle sur les rangs des sous dataframe\n",
    "            for _, row2 in dfsub.iterrows():\n",
    "                best_match = None\n",
    "                best_value = -1\n",
    "\n",
    "                for _, row1 in vfsub.iterrows():\n",
    "                    surface1 = row1['Surface Carrez du 1er lot']\n",
    "                    surface2 = row2['Surface_habitable_logement']\n",
    "\n",
    "                    #si surfaces identiques on match direct\n",
    "                    if surface1 == surface2:\n",
    "                        best_match = row1\n",
    "                        break\n",
    "\n",
    "                    #ecart inf à 5% et parmi les lignes avec des surfaces inf au seuil si jamais la valeur foncière est supérieure à celle de la ligne d'avant on la conserve pour avoir la plus grande\n",
    "                    if abs(surface1 - surface2) / max(surface1, surface2) < 0.05:\n",
    "                        valeur_fonciere = pd.to_numeric(str(row1.get('Valeur fonciere', 0)).replace(',', '.'), errors='coerce')\n",
    "                        if valeur_fonciere > best_value:\n",
    "                            best_value = valeur_fonciere\n",
    "                            best_match = row1\n",
    "\n",
    "                if best_match is not None:\n",
    "                    merged.append({**row2.to_dict(), **best_match.to_dict()})\n",
    "\n",
    "    #df des résultats fusionnés\n",
    "    df = pd.DataFrame(merged)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même fonction mais pour seuil de 10%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match3(vf, df):\n",
    "    merged = []\n",
    "\n",
    "    #boucle par département\n",
    "    for department in df['N°_département_(BAN)'].unique():  \n",
    "        print(f\"Traitement du département : {department}\")\n",
    "        \n",
    "        #filtre\n",
    "        vf_dept = vf[vf['Code departement']==department].copy()\n",
    "        df_dept = df[df['N°_département_(BAN)']==department].copy()\n",
    "\n",
    "        #normalisation adresses\n",
    "        vf_dept['Adresse'] = vf_dept['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "        vf_dept['Adresse_Normalisee'] = vf_dept.apply(lambda row: normalize_vf_address(row['Adresse'], row['Code departement']), axis=1)\n",
    "        df_dept['Adresse_Normalisee'] = df_dept['Adresse_(BAN)'].apply(normalize_address)\n",
    "\n",
    "        adresse_counts = vf_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique1 = list(adresse_counts[adresse_counts == 1].index)\n",
    "        doublons1 = list(adresse_counts[adresse_counts > 1].index)\n",
    "        final = unique1 + doublons1\n",
    "        set_final = set(final)\n",
    "\n",
    "        adresse_counts2 = df_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique2 = list(adresse_counts2[adresse_counts2 == 1].index)\n",
    "        doublons2 = list(adresse_counts2[adresse_counts2 > 1].index)\n",
    "        final2 = unique2 + doublons2\n",
    "        set_final2 = set(final2)\n",
    "\n",
    "        commun = set_final.intersection(set_final2)\n",
    "\n",
    "        vf_dept['Surface Carrez du 1er lot'] = pd.to_numeric(\n",
    "            vf_dept['Surface Carrez du 1er lot'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "        df_dept['Surface_habitable_logement'] = pd.to_numeric(\n",
    "            df_dept['Surface_habitable_logement'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "\n",
    "        for adresse in commun:\n",
    "            dfsub = df_dept[df_dept['Adresse_Normalisee'] == adresse]\n",
    "            vfsub = vf_dept[vf_dept['Adresse_Normalisee'] == adresse]\n",
    "\n",
    "            for _, row2 in dfsub.iterrows():\n",
    "                best_match = None\n",
    "                best_value = -1\n",
    "\n",
    "                for _, row1 in vfsub.iterrows():\n",
    "                    surface1 = row1['Surface Carrez du 1er lot']\n",
    "                    surface2 = row2['Surface_habitable_logement']\n",
    "\n",
    "                    #si surfaces identiques on match direct\n",
    "                    if surface1 == surface2:\n",
    "                        best_match = row1\n",
    "                        break\n",
    "\n",
    "                    #ecart inf à 10%\n",
    "                    if abs(surface1 - surface2) / max(surface1, surface2) < 0.1:\n",
    "                        valeur_fonciere = pd.to_numeric(str(row1.get('Valeur fonciere', 0)).replace(',', '.'), errors='coerce')\n",
    "                        if valeur_fonciere > best_value:\n",
    "                            best_value = valeur_fonciere\n",
    "                            best_match = row1\n",
    "\n",
    "                if best_match is not None:\n",
    "                    merged.append({**row2.to_dict(), **best_match.to_dict()})\n",
    "\n",
    "    #df des résultats fusionnés\n",
    "    df = pd.DataFrame(merged)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même fonction mais avec seuil de 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match4(vf, df):\n",
    "    merged = []\n",
    "\n",
    "\n",
    "    #boucle par département\n",
    "    for department in df['N°_département_(BAN)'].unique():  \n",
    "        print(f\"Traitement du département : {department}\")\n",
    "        \n",
    "        #filtre\n",
    "        vf_dept = vf[vf['Code departement']==department].copy()\n",
    "        df_dept = df[df['N°_département_(BAN)']==department].copy()\n",
    "\n",
    "        #normalisation adresses\n",
    "        vf_dept['Adresse'] = vf_dept['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "        vf_dept['Adresse_Normalisee'] = vf_dept.apply(lambda row: normalize_vf_address(row['Adresse'], row['Code departement']), axis=1)\n",
    "        df_dept['Adresse_Normalisee'] = df_dept['Adresse_(BAN)'].apply(normalize_address)\n",
    "\n",
    "        adresse_counts = vf_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique1 = list(adresse_counts[adresse_counts == 1].index)\n",
    "        doublons1 = list(adresse_counts[adresse_counts > 1].index)\n",
    "        final = unique1 + doublons1\n",
    "        set_final = set(final)\n",
    "\n",
    "        adresse_counts2 = df_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique2 = list(adresse_counts2[adresse_counts2 == 1].index)\n",
    "        doublons2 = list(adresse_counts2[adresse_counts2 > 1].index)\n",
    "        final2 = unique2 + doublons2\n",
    "        set_final2 = set(final2)\n",
    "\n",
    "        commun = set_final.intersection(set_final2)\n",
    "\n",
    "        vf_dept['Surface Carrez du 1er lot'] = pd.to_numeric(\n",
    "            vf_dept['Surface Carrez du 1er lot'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "        df_dept['Surface_habitable_logement'] = pd.to_numeric(\n",
    "            df_dept['Surface_habitable_logement'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "\n",
    "        for adresse in commun:\n",
    "            dfsub = df_dept[df_dept['Adresse_Normalisee'] == adresse]\n",
    "            vfsub = vf_dept[vf_dept['Adresse_Normalisee'] == adresse]\n",
    "\n",
    "            for _, row2 in dfsub.iterrows():\n",
    "                best_match = None\n",
    "                best_value = -1\n",
    "\n",
    "                for _, row1 in vfsub.iterrows():\n",
    "                    surface1 = row1['Surface Carrez du 1er lot']\n",
    "                    surface2 = row2['Surface_habitable_logement']\n",
    "\n",
    "                    #si surfaces identiques on match direct\n",
    "                    if surface1 == surface2:\n",
    "                        best_match = row1\n",
    "                        break\n",
    "\n",
    "                    #ecart inf à 3%\n",
    "                    if abs(surface1 - surface2) / max(surface1, surface2) < 0.03:\n",
    "                        valeur_fonciere = pd.to_numeric(str(row1.get('Valeur fonciere', 0)).replace(',', '.'), errors='coerce')\n",
    "                        if valeur_fonciere > best_value:\n",
    "                            best_value = valeur_fonciere\n",
    "                            best_match = row1\n",
    "\n",
    "                if best_match is not None:\n",
    "                    merged.append({**row2.to_dict(), **best_match.to_dict()})\n",
    "\n",
    "    #df des résultats fusionnés\n",
    "    df = pd.DataFrame(merged)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction pour compiler deux dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler les deux DataFrames\n",
    "def compiler_dataframes(df1, df2):\n",
    "    #concatène les deux DataFrames\n",
    "    df_compilé = pd.concat([df1, df2], ignore_index=True)\n",
    "    #supprime doublons\n",
    "    df_compilé = df_compilé.drop_duplicates()\n",
    "    return df_compilé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MATCHING ANNEE 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation des adresses dans le fichier vf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir explicitement toutes les colonnes en chaînes\n",
    "vf2022['Adresse'] = vf2022['No voie'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf2022['Type de voie'].fillna('').astype(str) + \" \" + \\\n",
    "                vf2022['Voie'].fillna('').astype(str) + \", \" + \\\n",
    "                vf2022['Code postal'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf2022['Commune'].fillna('').astype(str)\n",
    "\n",
    "# On crée la colonne Adresse\n",
    "\n",
    "vf2022['Adresse'] = vf2022['Adresse'].str.strip().replace(r'^\\s*$', None, regex=True)  # Supprime les adresses vides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sélectionne les données de 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_réception_DPE'] = pd.to_datetime(df['Date_réception_DPE'], errors='coerce')\n",
    "df2022 = df[df['Date_réception_DPE'].dt.year == 2022].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enlève les valeurs manquantes et on convertit le format du numéro de département."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf2022 = vf2022[vf['Code departement'].notna()]\n",
    "df2022 = df2022[df2022['N°_département_(BAN)'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf2022['Code departement'] = vf2022['Code departement'].astype(str)\n",
    "df2022.loc[:, 'N°_département_(BAN)'] = df2022['N°_département_(BAN)'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AVEC 5% POUR LES SURFACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 13\n",
      "Traitement du département : 92\n",
      "Traitement du département : 69\n",
      "Traitement du département : 03\n",
      "Traitement du département : 56\n",
      "Traitement du département : 75\n",
      "Traitement du département : 29\n",
      "Traitement du département : 91\n",
      "Traitement du département : 62\n",
      "Traitement du département : 21\n",
      "Traitement du département : 11\n",
      "Traitement du département : 02\n",
      "Traitement du département : 59\n",
      "Traitement du département : 94\n",
      "Traitement du département : 44\n",
      "Traitement du département : 50\n",
      "Traitement du département : 37\n",
      "Traitement du département : 81\n",
      "Traitement du département : 67\n",
      "Traitement du département : 93\n",
      "Traitement du département : 83\n",
      "Traitement du département : 63\n",
      "Traitement du département : 95\n",
      "Traitement du département : 76\n",
      "Traitement du département : 33\n",
      "Traitement du département : 78\n",
      "Traitement du département : 38\n",
      "Traitement du département : 51\n",
      "Traitement du département : 57\n",
      "Traitement du département : 77\n",
      "Traitement du département : 35\n",
      "Traitement du département : 54\n",
      "Traitement du département : 80\n",
      "Traitement du département : 36\n",
      "Traitement du département : 73\n",
      "Traitement du département : 31\n",
      "Traitement du département : 49\n",
      "Traitement du département : 60\n",
      "Traitement du département : 45\n",
      "Traitement du département : 14\n",
      "Traitement du département : 74\n",
      "Traitement du département : 41\n",
      "Traitement du département : 28\n",
      "Traitement du département : 10\n",
      "Traitement du département : 30\n",
      "Traitement du département : 58\n",
      "Traitement du département : 34\n",
      "Traitement du département : 12\n",
      "Traitement du département : 64\n",
      "Traitement du département : 55\n",
      "Traitement du département : 84\n",
      "Traitement du département : 24\n",
      "Traitement du département : 61\n",
      "Traitement du département : 27\n",
      "Traitement du département : 47\n",
      "Traitement du département : 89\n",
      "Traitement du département : 85\n",
      "Traitement du département : 87\n",
      "Traitement du département : 17\n",
      "Traitement du département : 06\n",
      "Traitement du département : 16\n",
      "Traitement du département : 07\n",
      "Traitement du département : 42\n",
      "Traitement du département : 72\n",
      "Traitement du département : 79\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 15\n",
      "Traitement du département : 25\n",
      "Traitement du département : 04\n",
      "Traitement du département : 23\n",
      "Traitement du département : 01\n",
      "Traitement du département : 66\n",
      "Traitement du département : 68\n",
      "Traitement du département : 53\n",
      "Traitement du département : 26\n",
      "Traitement du département : 05\n",
      "Traitement du département : 08\n",
      "Traitement du département : 18\n",
      "Traitement du département : 22\n",
      "Traitement du département : 40\n",
      "Traitement du département : 32\n",
      "Traitement du département : 88\n",
      "Traitement du département : 52\n",
      "Traitement du département : 43\n",
      "Traitement du département : 19\n",
      "Traitement du département : 71\n",
      "Traitement du département : 90\n",
      "Traitement du département : 86\n",
      "Traitement du département : 39\n",
      "Traitement du département : 65\n",
      "Traitement du département : 82\n",
      "Traitement du département : 09\n",
      "Traitement du département : 46\n",
      "Traitement du département : 48\n",
      "Traitement du département : 70\n",
      "Traitement du département : 972\n",
      "Traitement du département : 974\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 971\n",
      "Traitement du département : 976\n",
      "Traitement du département : 973\n",
      "Traitement du département : 988\n"
     ]
    }
   ],
   "source": [
    "#application fonction\n",
    "test2 = test_match2(vf2022, df2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques lignes sont en doublons dans le résultat final, nous pouvons les enlever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = test2.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result5%.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77673\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous obtenons un dataframe de 77673 lignes pour les logements existants avec un seuil de 5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AVEC 10% POUR LES SURFACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 13\n",
      "Traitement du département : 92\n",
      "Traitement du département : 69\n",
      "Traitement du département : 03\n",
      "Traitement du département : 56\n",
      "Traitement du département : 75\n",
      "Traitement du département : 29\n",
      "Traitement du département : 91\n",
      "Traitement du département : 62\n",
      "Traitement du département : 21\n",
      "Traitement du département : 11\n",
      "Traitement du département : 02\n",
      "Traitement du département : 59\n",
      "Traitement du département : 94\n",
      "Traitement du département : 44\n",
      "Traitement du département : 50\n",
      "Traitement du département : 37\n",
      "Traitement du département : 81\n",
      "Traitement du département : 67\n",
      "Traitement du département : 93\n",
      "Traitement du département : 83\n",
      "Traitement du département : 63\n",
      "Traitement du département : 95\n",
      "Traitement du département : 76\n",
      "Traitement du département : 33\n",
      "Traitement du département : 78\n",
      "Traitement du département : 38\n",
      "Traitement du département : 51\n",
      "Traitement du département : 57\n",
      "Traitement du département : 77\n",
      "Traitement du département : 35\n",
      "Traitement du département : 54\n",
      "Traitement du département : 80\n",
      "Traitement du département : 36\n",
      "Traitement du département : 73\n",
      "Traitement du département : 31\n",
      "Traitement du département : 49\n",
      "Traitement du département : 60\n",
      "Traitement du département : 45\n",
      "Traitement du département : 14\n",
      "Traitement du département : 74\n",
      "Traitement du département : 41\n",
      "Traitement du département : 28\n",
      "Traitement du département : 10\n",
      "Traitement du département : 30\n",
      "Traitement du département : 58\n",
      "Traitement du département : 34\n",
      "Traitement du département : 12\n",
      "Traitement du département : 64\n",
      "Traitement du département : 55\n",
      "Traitement du département : 84\n",
      "Traitement du département : 24\n",
      "Traitement du département : 61\n",
      "Traitement du département : 27\n",
      "Traitement du département : 47\n",
      "Traitement du département : 89\n",
      "Traitement du département : 85\n",
      "Traitement du département : 87\n",
      "Traitement du département : 17\n",
      "Traitement du département : 06\n",
      "Traitement du département : 16\n",
      "Traitement du département : 07\n",
      "Traitement du département : 42\n",
      "Traitement du département : 72\n",
      "Traitement du département : 79\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 15\n",
      "Traitement du département : 25\n",
      "Traitement du département : 04\n",
      "Traitement du département : 23\n",
      "Traitement du département : 01\n",
      "Traitement du département : 66\n",
      "Traitement du département : 68\n",
      "Traitement du département : 53\n",
      "Traitement du département : 26\n",
      "Traitement du département : 05\n",
      "Traitement du département : 08\n",
      "Traitement du département : 18\n",
      "Traitement du département : 22\n",
      "Traitement du département : 40\n",
      "Traitement du département : 32\n",
      "Traitement du département : 88\n",
      "Traitement du département : 52\n",
      "Traitement du département : 43\n",
      "Traitement du département : 19\n",
      "Traitement du département : 71\n",
      "Traitement du département : 90\n",
      "Traitement du département : 86\n",
      "Traitement du département : 39\n",
      "Traitement du département : 65\n",
      "Traitement du département : 82\n",
      "Traitement du département : 09\n",
      "Traitement du département : 46\n",
      "Traitement du département : 48\n",
      "Traitement du département : 70\n",
      "Traitement du département : 972\n",
      "Traitement du département : 974\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 971\n",
      "Traitement du département : 976\n",
      "Traitement du département : 973\n",
      "Traitement du département : 988\n"
     ]
    }
   ],
   "source": [
    "#application fonction\n",
    "test3 = test_match3(vf2022, df2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même raisonnement que précédemment on enlève les doublons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10 = test3.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89539\n"
     ]
    }
   ],
   "source": [
    "print(len(result10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10.to_csv(\"result10%.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un dataframe plus important avec 89 539 lignes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST SEUIL DE 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#application fonction\n",
    "test4 = test_match4(vf2022, df2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = test4.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69752\n"
     ]
    }
   ],
   "source": [
    "print(len(result3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3.to_csv(\"result3%.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons seulement pouvoir compiler les données pour les années : 2021 et 2022 car nous n'avons pas les données valeurs foncières de 2023. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise le même raisonnement que pour 2022 on formate les données. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée la colonne adresse dans le dataframe vf pour que l'adresse soit utilisable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir explicitement toutes les colonnes en chaînes\n",
    "vf2021['Adresse'] = vf2021['No voie'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf2021['Type de voie'].fillna('').astype(str) + \" \" + \\\n",
    "                vf2021['Voie'].fillna('').astype(str) + \", \" + \\\n",
    "                vf2021['Code postal'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf2021['Commune'].fillna('').astype(str)\n",
    "\n",
    "vf2021['Adresse'] = vf2021['Adresse'].str.strip().replace(r'^\\s*$', None, regex=True)  # Supprime les adresses vides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne garde que les données de 2021. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_réception_DPE'] = pd.to_datetime(df['Date_réception_DPE'], errors='coerce')\n",
    "df2021 = df[df['Date_réception_DPE'].dt.year == 2021].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enlève les valeurs manquantes et on convertit le format du numéro de département. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf2021 = vf2021[vf2021['Code departement'].notna()]\n",
    "df2021 = df2021[df2021['N°_département_(BAN)'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf2021['Code departement'] = vf2021['Code departement'].astype(str)\n",
    "df2021.loc[:, 'N°_département_(BAN)'] = df2021['N°_département_(BAN)'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATCHING 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 25\n",
      "Traitement du département : 44\n",
      "Traitement du département : 36\n",
      "Traitement du département : 29\n",
      "Traitement du département : 43\n",
      "Traitement du département : 06\n",
      "Traitement du département : 88\n",
      "Traitement du département : 78\n",
      "Traitement du département : 14\n",
      "Traitement du département : 80\n",
      "Traitement du département : 54\n",
      "Traitement du département : 82\n",
      "Traitement du département : 49\n",
      "Traitement du département : 86\n",
      "Traitement du département : 52\n",
      "Traitement du département : 64\n",
      "Traitement du département : 59\n",
      "Traitement du département : 77\n",
      "Traitement du département : 72\n",
      "Traitement du département : 67\n",
      "Traitement du département : 60\n",
      "Traitement du département : 89\n",
      "Traitement du département : 41\n",
      "Traitement du département : 30\n",
      "Traitement du département : 69\n",
      "Traitement du département : 81\n",
      "Traitement du département : 85\n",
      "Traitement du département : 57\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 76\n",
      "Traitement du département : 35\n",
      "Traitement du département : 56\n",
      "Traitement du département : 40\n",
      "Traitement du département : 27\n",
      "Traitement du département : 68\n",
      "Traitement du département : 47\n",
      "Traitement du département : 79\n",
      "Traitement du département : 73\n",
      "Traitement du département : 62\n",
      "Traitement du département : 58\n",
      "Traitement du département : 22\n",
      "Traitement du département : 08\n",
      "Traitement du département : 63\n",
      "Traitement du département : 42\n",
      "Traitement du département : 74\n",
      "Traitement du département : 38\n",
      "Traitement du département : 65\n",
      "Traitement du département : 84\n",
      "Traitement du département : 26\n",
      "Traitement du département : 31\n",
      "Traitement du département : 83\n",
      "Traitement du département : 46\n",
      "Traitement du département : 24\n",
      "Traitement du département : 28\n",
      "Traitement du département : 11\n",
      "Traitement du département : 92\n",
      "Traitement du département : 87\n",
      "Traitement du département : 13\n",
      "Traitement du département : 51\n",
      "Traitement du département : 50\n",
      "Traitement du département : 75\n",
      "Traitement du département : 04\n",
      "Traitement du département : 91\n",
      "Traitement du département : 01\n",
      "Traitement du département : 71\n",
      "Traitement du département : 05\n",
      "Traitement du département : 21\n",
      "Traitement du département : 45\n",
      "Traitement du département : 93\n",
      "Traitement du département : 32\n",
      "Traitement du département : 61\n",
      "Traitement du département : 17\n",
      "Traitement du département : 55\n",
      "Traitement du département : 95\n",
      "Traitement du département : 33\n",
      "Traitement du département : 39\n",
      "Traitement du département : 19\n",
      "Traitement du département : 37\n",
      "Traitement du département : 53\n",
      "Traitement du département : 70\n",
      "Traitement du département : 94\n",
      "Traitement du département : 90\n",
      "Traitement du département : 66\n",
      "Traitement du département : 34\n",
      "Traitement du département : 16\n",
      "Traitement du département : 03\n",
      "Traitement du département : 18\n",
      "Traitement du département : 02\n",
      "Traitement du département : 07\n",
      "Traitement du département : 15\n",
      "Traitement du département : 09\n",
      "Traitement du département : 12\n",
      "Traitement du département : 23\n",
      "Traitement du département : 10\n",
      "Traitement du département : 972\n",
      "Traitement du département : 48\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 974\n",
      "Traitement du département : 973\n",
      "Traitement du département : 976\n",
      "Traitement du département : 971\n"
     ]
    }
   ],
   "source": [
    "dfexistant2021 = test_match2(vf2021, df2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexistant2021 = dfexistant2021.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21411\n"
     ]
    }
   ],
   "source": [
    "print(len(dfexistant2021))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un fichier final pour le matching à 5% avec 21 411 lignes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA FRAME FINAL POUR 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère les dataframe à 5% pour les années 2021 et 2022. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/ymcp1z4s7n77n5bhz3q_hgqc0000gn/T/ipykernel_1211/1554524822.py:1: DtypeWarning: Columns (14,15,30,52,58,60,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(\"result5%_2021_compilé.csv\")\n",
      "/var/folders/bf/ymcp1z4s7n77n5bhz3q_hgqc0000gn/T/ipykernel_1211/1554524822.py:2: DtypeWarning: Columns (14,15,30,52,58,60,62,65,67,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(\"result5%_2022_compilé.csv\")\n"
     ]
    }
   ],
   "source": [
    "df1 = dfexistant2021\n",
    "df2 = pd.read_csv(\"result5%.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffinal5 = compiler_dataframes(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la fonction compiler et on exporte le fichier au format csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffinal5.to_csv(\"result5%_surfacecarrez.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AVEC SURFACE REELLE BATIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jusqu'à présent nous avions utilisé la colonne surface loi carrez pour le matching, nous pouvons essayer de considérer la surface réelle du bâtiment. Il faut donc modifier les codes utilisés. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même code mais changement de colonne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_matchbati(vf, df):\n",
    "    merged = []\n",
    "\n",
    "\n",
    "    #boucle par département\n",
    "    for department in df['N°_département_(BAN)'].unique():  \n",
    "        print(f\"Traitement du département : {department}\")\n",
    "        \n",
    "        #filtre\n",
    "        vf_dept = vf[vf['Code departement']==department].copy()\n",
    "        df_dept = df[df['N°_département_(BAN)']==department].copy()\n",
    "\n",
    "        #normalisation adresses\n",
    "        vf_dept['Adresse'] = vf_dept['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "        vf_dept['Adresse_Normalisee'] = vf_dept.apply(lambda row: normalize_vf_address(row['Adresse'], row['Code departement']), axis=1)\n",
    "        df_dept['Adresse_Normalisee'] = df_dept['Adresse_(BAN)'].apply(normalize_address)\n",
    "\n",
    "        adresse_counts = vf_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique1 = list(adresse_counts[adresse_counts == 1].index)\n",
    "        doublons1 = list(adresse_counts[adresse_counts > 1].index)\n",
    "        final = unique1 + doublons1\n",
    "        set_final = set(final)\n",
    "\n",
    "        adresse_counts2 = df_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique2 = list(adresse_counts2[adresse_counts2 == 1].index)\n",
    "        doublons2 = list(adresse_counts2[adresse_counts2 > 1].index)\n",
    "        final2 = unique2 + doublons2\n",
    "        set_final2 = set(final2)\n",
    "\n",
    "        commun = set_final.intersection(set_final2)\n",
    "\n",
    "        vf_dept['Surface reelle bati'] = pd.to_numeric(vf_dept['Surface reelle bati'], errors='coerce')\n",
    "        vf_dept = vf_dept[vf_dept['Surface reelle bati'].notna() & (vf_dept['Surface reelle bati'] > 0)]\n",
    "        df_dept['Surface_habitable_logement'] = pd.to_numeric(\n",
    "            df_dept['Surface_habitable_logement'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "\n",
    "        for adresse in commun:\n",
    "            dfsub = df_dept[df_dept['Adresse_Normalisee'] == adresse]\n",
    "            vfsub = vf_dept[vf_dept['Adresse_Normalisee'] == adresse]\n",
    "\n",
    "            for _, row2 in dfsub.iterrows():\n",
    "                best_match = None\n",
    "                best_value = -1\n",
    "\n",
    "                for _, row1 in vfsub.iterrows():\n",
    "                    surface1 = row1['Surface reelle bati']\n",
    "                    surface2 = row2['Surface_habitable_logement']\n",
    "\n",
    "                    #si surfaces identiques on match direct\n",
    "                    if surface1 == surface2:\n",
    "                        best_match = row1\n",
    "                        break\n",
    "\n",
    "                    #ecart inf à 5%\n",
    "                    if abs(surface1 - surface2) / max(surface1, surface2) < 0.05:\n",
    "                        valeur_fonciere = pd.to_numeric(str(row1.get('Valeur fonciere', 0)).replace(',', '.'), errors='coerce')\n",
    "                        if valeur_fonciere > best_value:\n",
    "                            best_value = valeur_fonciere\n",
    "                            best_match = row1\n",
    "\n",
    "                if best_match is not None:\n",
    "                    merged.append({**row2.to_dict(), **best_match.to_dict()})\n",
    "\n",
    "    #df des résultats fusionnés\n",
    "    df = pd.DataFrame(merged)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 13\n",
      "Traitement du département : 92\n",
      "Traitement du département : 69\n",
      "Traitement du département : 03\n",
      "Traitement du département : 56\n",
      "Traitement du département : 75\n",
      "Traitement du département : 29\n",
      "Traitement du département : 91\n",
      "Traitement du département : 62\n",
      "Traitement du département : 21\n",
      "Traitement du département : 11\n",
      "Traitement du département : 02\n",
      "Traitement du département : 59\n",
      "Traitement du département : 94\n",
      "Traitement du département : 44\n",
      "Traitement du département : 50\n",
      "Traitement du département : 37\n",
      "Traitement du département : 81\n",
      "Traitement du département : 67\n",
      "Traitement du département : 93\n",
      "Traitement du département : 83\n",
      "Traitement du département : 63\n",
      "Traitement du département : 95\n",
      "Traitement du département : 76\n",
      "Traitement du département : 33\n",
      "Traitement du département : 78\n",
      "Traitement du département : 38\n",
      "Traitement du département : 51\n",
      "Traitement du département : 57\n",
      "Traitement du département : 77\n",
      "Traitement du département : 35\n",
      "Traitement du département : 54\n",
      "Traitement du département : 80\n",
      "Traitement du département : 36\n",
      "Traitement du département : 73\n",
      "Traitement du département : 31\n",
      "Traitement du département : 49\n",
      "Traitement du département : 60\n",
      "Traitement du département : 45\n",
      "Traitement du département : 14\n",
      "Traitement du département : 74\n",
      "Traitement du département : 41\n",
      "Traitement du département : 28\n",
      "Traitement du département : 10\n",
      "Traitement du département : 30\n",
      "Traitement du département : 58\n",
      "Traitement du département : 34\n",
      "Traitement du département : 12\n",
      "Traitement du département : 64\n",
      "Traitement du département : 55\n",
      "Traitement du département : 84\n",
      "Traitement du département : 24\n",
      "Traitement du département : 61\n",
      "Traitement du département : 27\n",
      "Traitement du département : 47\n",
      "Traitement du département : 89\n",
      "Traitement du département : 85\n",
      "Traitement du département : 87\n",
      "Traitement du département : 17\n",
      "Traitement du département : 06\n",
      "Traitement du département : 16\n",
      "Traitement du département : 07\n",
      "Traitement du département : 42\n",
      "Traitement du département : 72\n",
      "Traitement du département : 79\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 15\n",
      "Traitement du département : 25\n",
      "Traitement du département : 04\n",
      "Traitement du département : 23\n",
      "Traitement du département : 01\n",
      "Traitement du département : 66\n",
      "Traitement du département : 68\n",
      "Traitement du département : 53\n",
      "Traitement du département : 26\n",
      "Traitement du département : 05\n",
      "Traitement du département : 08\n",
      "Traitement du département : 18\n",
      "Traitement du département : 22\n",
      "Traitement du département : 40\n",
      "Traitement du département : 32\n",
      "Traitement du département : 88\n",
      "Traitement du département : 52\n",
      "Traitement du département : 43\n",
      "Traitement du département : 19\n",
      "Traitement du département : 71\n",
      "Traitement du département : 90\n",
      "Traitement du département : 86\n",
      "Traitement du département : 39\n",
      "Traitement du département : 65\n",
      "Traitement du département : 82\n",
      "Traitement du département : 09\n",
      "Traitement du département : 46\n",
      "Traitement du département : 48\n",
      "Traitement du département : 70\n",
      "Traitement du département : 972\n",
      "Traitement du département : 974\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 971\n",
      "Traitement du département : 976\n",
      "Traitement du département : 973\n",
      "Traitement du département : 988\n"
     ]
    }
   ],
   "source": [
    "testbati = test_matchbati(vf2022, df2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsurfacebati5 = testbati.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142926\n"
     ]
    }
   ],
   "source": [
    "print(len(resultsurfacebati5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un dataframe plus grand avec 142 926 lignes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 25\n",
      "Traitement du département : 44\n",
      "Traitement du département : 36\n",
      "Traitement du département : 29\n",
      "Traitement du département : 43\n",
      "Traitement du département : 06\n",
      "Traitement du département : 88\n",
      "Traitement du département : 78\n",
      "Traitement du département : 14\n",
      "Traitement du département : 80\n",
      "Traitement du département : 54\n",
      "Traitement du département : 82\n",
      "Traitement du département : 49\n",
      "Traitement du département : 86\n",
      "Traitement du département : 52\n",
      "Traitement du département : 64\n",
      "Traitement du département : 59\n",
      "Traitement du département : 77\n",
      "Traitement du département : 72\n",
      "Traitement du département : 67\n",
      "Traitement du département : 60\n",
      "Traitement du département : 89\n",
      "Traitement du département : 41\n",
      "Traitement du département : 30\n",
      "Traitement du département : 69\n",
      "Traitement du département : 81\n",
      "Traitement du département : 85\n",
      "Traitement du département : 57\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 76\n",
      "Traitement du département : 35\n",
      "Traitement du département : 56\n",
      "Traitement du département : 40\n",
      "Traitement du département : 27\n",
      "Traitement du département : 68\n",
      "Traitement du département : 47\n",
      "Traitement du département : 79\n",
      "Traitement du département : 73\n",
      "Traitement du département : 62\n",
      "Traitement du département : 58\n",
      "Traitement du département : 22\n",
      "Traitement du département : 08\n",
      "Traitement du département : 63\n",
      "Traitement du département : 42\n",
      "Traitement du département : 74\n",
      "Traitement du département : 38\n",
      "Traitement du département : 65\n",
      "Traitement du département : 84\n",
      "Traitement du département : 26\n",
      "Traitement du département : 31\n",
      "Traitement du département : 83\n",
      "Traitement du département : 46\n",
      "Traitement du département : 24\n",
      "Traitement du département : 28\n",
      "Traitement du département : 11\n",
      "Traitement du département : 92\n",
      "Traitement du département : 87\n",
      "Traitement du département : 13\n",
      "Traitement du département : 51\n",
      "Traitement du département : 50\n",
      "Traitement du département : 75\n",
      "Traitement du département : 04\n",
      "Traitement du département : 91\n",
      "Traitement du département : 01\n",
      "Traitement du département : 71\n",
      "Traitement du département : 05\n",
      "Traitement du département : 21\n",
      "Traitement du département : 45\n",
      "Traitement du département : 93\n",
      "Traitement du département : 32\n",
      "Traitement du département : 61\n",
      "Traitement du département : 17\n",
      "Traitement du département : 55\n",
      "Traitement du département : 95\n",
      "Traitement du département : 33\n",
      "Traitement du département : 39\n",
      "Traitement du département : 19\n",
      "Traitement du département : 37\n",
      "Traitement du département : 53\n",
      "Traitement du département : 70\n",
      "Traitement du département : 94\n",
      "Traitement du département : 90\n",
      "Traitement du département : 66\n",
      "Traitement du département : 34\n",
      "Traitement du département : 16\n",
      "Traitement du département : 03\n",
      "Traitement du département : 18\n",
      "Traitement du département : 02\n",
      "Traitement du département : 07\n",
      "Traitement du département : 15\n",
      "Traitement du département : 09\n",
      "Traitement du département : 12\n",
      "Traitement du département : 23\n",
      "Traitement du département : 10\n",
      "Traitement du département : 972\n",
      "Traitement du département : 48\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 974\n",
      "Traitement du département : 973\n",
      "Traitement du département : 976\n",
      "Traitement du département : 971\n"
     ]
    }
   ],
   "source": [
    "testbati2021 = test_matchbati(vf2021, df2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2021surfacebati5 = testbati2021.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37772\n"
     ]
    }
   ],
   "source": [
    "print(len(result2021surfacebati5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient encore une fois un dataframe plus grand de 37 772 lignes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPILER LES DEUX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On compile les deux fichiers obtenus pour le matching à 5% avec la surface réelle du batiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsurfacereelle5 = compiler_dataframes(resultsurfacebati5, result2021surfacebati5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180698\n"
     ]
    }
   ],
   "source": [
    "print(len(resultsurfacereelle5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2021surfacebati5.to_csv(\"result5%_surfacereellebati.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un fichier plus grand que celui obtenu avec la surface loi carrez. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
