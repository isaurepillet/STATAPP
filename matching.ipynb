{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from postal.expand import expand_address\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT DES DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4537525"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/DPE/DPE_ADEME/dpe-v2-logements-existants.csv\",\n",
    "    sep=\",\",  # Séparateur CSV\n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False)\n",
    "\n",
    "df['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's3_connection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m s3 = \u001b[43ms3_connection\u001b[49m()\n",
      "\u001b[31mNameError\u001b[39m: name 's3_connection' is not defined"
     ]
    }
   ],
   "source": [
    "s3 = s3_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/STATAPP/helpers.py:35: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_in, usecols=columns_to_select, dtype=dtype_spec, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "path_logements_existants = \"clichere/diffusion/DPE/DPE_ADEME/dpe-v2-logements-existants.csv\"\n",
    "df = s3.read_file_from_s3(path_logements_existants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537952"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/DPE/DPE_ADEME/dpe-v2-logements-neufs.csv\",\n",
    "    sep=\",\",  # Séparateur CSV\n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False)\n",
    "\n",
    "df2['Date_réception_DPE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/STATAPP/helpers.py:35: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(file_in, usecols=columns_to_select, dtype=dtype_spec, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "path_logements_existants = \"clichere/diffusion/DPE/DPE_ADEME/dpe-v2-logements-existants.csv\"\n",
    "df2 = s3.read_file_from_s3(path_logements_existants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/ValeursFoncieres/valeursfoncieres-2022.txt\",\n",
    "    sep=\"|\",  \n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyxia/STATAPP/helpers.py:35: DtypeWarning: Columns (18,23,24,26,28,29,31,33,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_in, usecols=columns_to_select, dtype=dtype_spec, sep=sep)\n"
     ]
    }
   ],
   "source": [
    "path_valeursfoncieres_2022 = \"clichere/diffusion/Valeursfoncières/valeursfoncieres-2022.txt\"\n",
    "vf = s3.read_file_from_s3(path_valeursfoncieres_2022, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir explicitement toutes les colonnes en chaînes\n",
    "vf['Adresse'] = vf['No voie'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf['Type de voie'].fillna('').astype(str) + \" \" + \\\n",
    "                vf['Voie'].fillna('').astype(str) + \", \" + \\\n",
    "                vf['Code postal'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf['Commune'].fillna('').astype(str)\n",
    "\n",
    "vf['Adresse'] = vf['Adresse'].str.strip().replace(r'^\\s*$', None, regex=True)  # Supprime les adresses vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_address(address):\n",
    "    if pd.isna(address) or address.strip() == '':\n",
    "        return None  \n",
    "    try:\n",
    "        normalized = expand_address(address)  \n",
    "        return normalized[0] if normalized else None  # Ne garde que la première version\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec l'adresse '{address}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_réception_DPE'] = pd.to_datetime(df['Date_réception_DPE'], errors='coerce')\n",
    "df = df[df['Date_réception_DPE'].dt.year == 2022].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = vf[vf['Code postal'].notna()]\n",
    "df = df[df['N°_département_(BAN)'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf['Code postal'] = vf['Code postal'].astype(int).astype(str)\n",
    "df.loc[:, 'N°_département_(BAN)'] = df['N°_département_(BAN)'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_vf_address(address, code_postal):\n",
    "    \"\"\" Normalise l'adresse et supprime l'arrondissement après 'PARIS' uniquement si le département est 75. \"\"\"\n",
    "    normalized_address = normalize_address(address)  \n",
    "\n",
    "    if pd.notna(normalized_address) and str(code_postal).startswith(\"75\"):\n",
    "        # Supprime le numéro après \"PARIS\" uniquement pour le département 75\n",
    "        normalized_address = re.sub(r'(paris) \\d{2}$', r'\\1', normalized_address, flags=re.IGNORECASE)\n",
    "    \n",
    "    return normalized_address\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AVEC 5% POUR LES SURFACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_match2(vf, df):\n",
    "    merged = []\n",
    "\n",
    "\n",
    "    #boucle par département\n",
    "    for department in df['N°_département_(BAN)'].unique():  \n",
    "        print(f\"Traitement du département : {department}\")\n",
    "        \n",
    "        #filtre\n",
    "        vf_dept = vf[vf['Code postal'].astype(str).str.startswith(department)].copy()\n",
    "        df_dept = df[df['N°_département_(BAN)']==department].copy()\n",
    "\n",
    "        #normalisation adresses\n",
    "        vf_dept['Adresse'] = vf_dept['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "        vf_dept['Adresse_Normalisee'] = vf_dept.apply(lambda row: normalize_vf_address(row['Adresse'], row['Code postal']), axis=1)\n",
    "        df_dept['Adresse_Normalisee'] = df_dept['Adresse_(BAN)'].apply(normalize_address)\n",
    "\n",
    "        adresse_counts = vf_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique1 = list(adresse_counts[adresse_counts == 1].index)\n",
    "        doublons1 = list(adresse_counts[adresse_counts > 1].index)\n",
    "        final = unique1 + doublons1\n",
    "        set_final = set(final)\n",
    "\n",
    "        adresse_counts2 = df_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique2 = list(adresse_counts2[adresse_counts2 == 1].index)\n",
    "        doublons2 = list(adresse_counts2[adresse_counts2 > 1].index)\n",
    "        final2 = unique2 + doublons2\n",
    "        set_final2 = set(final2)\n",
    "\n",
    "        commun = set_final.intersection(set_final2)\n",
    "\n",
    "        vf_dept['Surface Carrez du 1er lot'] = pd.to_numeric(\n",
    "            vf_dept['Surface Carrez du 1er lot'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "        df_dept['Surface_habitable_logement'] = pd.to_numeric(\n",
    "            df_dept['Surface_habitable_logement'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "\n",
    "        for adresse in commun:\n",
    "            dfsub = df_dept[df_dept['Adresse_Normalisee'] == adresse]\n",
    "            vfsub = vf_dept[vf_dept['Adresse_Normalisee'] == adresse]\n",
    "\n",
    "            for _, row2 in dfsub.iterrows():\n",
    "                best_match = None\n",
    "                best_value = -1\n",
    "\n",
    "                for _, row1 in vfsub.iterrows():\n",
    "                    surface1 = row1['Surface Carrez du 1er lot']\n",
    "                    surface2 = row2['Surface_habitable_logement']\n",
    "\n",
    "                    #si surfaces identiques on match direct\n",
    "                    if surface1 == surface2:\n",
    "                        best_match = row1\n",
    "                        break\n",
    "\n",
    "                    #ecart inf à 5%\n",
    "                    if abs(surface1 - surface2) / max(surface1, surface2) < 0.05:\n",
    "                        valeur_fonciere = pd.to_numeric(str(row1.get('Valeur fonciere', 0)).replace(',', '.'), errors='coerce')\n",
    "                        if valeur_fonciere > best_value:\n",
    "                            best_value = valeur_fonciere\n",
    "                            best_match = row1\n",
    "\n",
    "                if best_match is not None:\n",
    "                    merged.append({**row2.to_dict(), **best_match.to_dict()})\n",
    "\n",
    "    #df des résultats fusionnés\n",
    "    df = pd.DataFrame(merged)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 13\n",
      "Traitement du département : 92\n",
      "Traitement du département : 69\n",
      "Traitement du département : 03\n",
      "Traitement du département : 56\n",
      "Traitement du département : 75\n",
      "Traitement du département : 29\n",
      "Traitement du département : 91\n",
      "Traitement du département : 62\n",
      "Traitement du département : 21\n",
      "Traitement du département : 11\n",
      "Traitement du département : 02\n",
      "Traitement du département : 59\n",
      "Traitement du département : 94\n",
      "Traitement du département : 44\n",
      "Traitement du département : 50\n",
      "Traitement du département : 37\n",
      "Traitement du département : 81\n",
      "Traitement du département : 67\n",
      "Traitement du département : 93\n",
      "Traitement du département : 83\n",
      "Traitement du département : 63\n",
      "Traitement du département : 95\n",
      "Traitement du département : 76\n",
      "Traitement du département : 33\n",
      "Traitement du département : 78\n",
      "Traitement du département : 38\n",
      "Traitement du département : 51\n",
      "Traitement du département : 57\n",
      "Traitement du département : 77\n",
      "Traitement du département : 35\n",
      "Traitement du département : 54\n",
      "Traitement du département : 80\n",
      "Traitement du département : 36\n",
      "Traitement du département : 73\n",
      "Traitement du département : 31\n",
      "Traitement du département : 49\n",
      "Traitement du département : 60\n",
      "Traitement du département : 45\n",
      "Traitement du département : 14\n",
      "Traitement du département : 74\n",
      "Traitement du département : 41\n",
      "Traitement du département : 28\n",
      "Traitement du département : 10\n",
      "Traitement du département : 30\n",
      "Traitement du département : 58\n",
      "Traitement du département : 34\n",
      "Traitement du département : 12\n",
      "Traitement du département : 64\n",
      "Traitement du département : 55\n",
      "Traitement du département : 84\n",
      "Traitement du département : 24\n",
      "Traitement du département : 61\n",
      "Traitement du département : 27\n",
      "Traitement du département : 47\n",
      "Traitement du département : 89\n",
      "Traitement du département : 85\n",
      "Traitement du département : 87\n",
      "Traitement du département : 17\n",
      "Traitement du département : 06\n",
      "Traitement du département : 16\n",
      "Traitement du département : 07\n",
      "Traitement du département : 42\n",
      "Traitement du département : 72\n",
      "Traitement du département : 79\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 15\n",
      "Traitement du département : 25\n",
      "Traitement du département : 04\n",
      "Traitement du département : 23\n",
      "Traitement du département : 01\n",
      "Traitement du département : 66\n",
      "Traitement du département : 68\n",
      "Traitement du département : 53\n",
      "Traitement du département : 26\n",
      "Traitement du département : 05\n",
      "Traitement du département : 08\n",
      "Traitement du département : 18\n",
      "Traitement du département : 22\n",
      "Traitement du département : 40\n",
      "Traitement du département : 32\n",
      "Traitement du département : 88\n",
      "Traitement du département : 52\n",
      "Traitement du département : 43\n",
      "Traitement du département : 19\n",
      "Traitement du département : 71\n",
      "Traitement du département : 90\n",
      "Traitement du département : 86\n",
      "Traitement du département : 39\n",
      "Traitement du département : 65\n",
      "Traitement du département : 82\n",
      "Traitement du département : 09\n",
      "Traitement du département : 46\n",
      "Traitement du département : 48\n",
      "Traitement du département : 70\n",
      "Traitement du département : 972\n",
      "Traitement du département : 974\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 971\n",
      "Traitement du département : 976\n",
      "Traitement du département : 973\n",
      "Traitement du département : 988\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#application fonction\n",
    "test2 = test_match2(vf, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.to_csv(\"testfinal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3764712\n"
     ]
    }
   ],
   "source": [
    "print(len(vf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2405317\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70665\n"
     ]
    }
   ],
   "source": [
    "print(len(test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etudes doublons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_179738/2613097225.py:1: DtypeWarning: Columns (15,58,60,62,65,67,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_final = pd.read_csv(\"testfinal.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.read_csv(\"testfinal.csv\")\n",
    "\n",
    "# Identifier les doublons (conservés malgré le drop dans le script précédent ?)\n",
    "doublons = df_final[df_final.duplicated(\n",
    "    subset=['Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere'], \n",
    "    keep=False\n",
    ")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "#display(doublons.sort_values(by='Adresse_Normalisee').head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = test2.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result5%.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77148\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_179738/3911531778.py:1: DtypeWarning: Columns (15,58,60,62,65,67,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_final = pd.read_csv(\"testfinal.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.read_csv(\"testfinal.csv\")\n",
    "\n",
    "# Identifier les doublons (conservés malgré le drop dans le script précédent ?)\n",
    "doublons1 = df_final[df_final.duplicated(\n",
    "    subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\"], \n",
    "    keep=False\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#display(doublons1.sort_values(by='Adresse_Normalisee').head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AVEC 10% POUR LES SURFACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 13\n",
      "Traitement du département : 92\n",
      "Traitement du département : 69\n",
      "Traitement du département : 03\n",
      "Traitement du département : 56\n",
      "Traitement du département : 75\n",
      "Traitement du département : 29\n",
      "Traitement du département : 91\n",
      "Traitement du département : 62\n",
      "Traitement du département : 21\n",
      "Traitement du département : 11\n",
      "Traitement du département : 02\n",
      "Traitement du département : 59\n",
      "Traitement du département : 94\n",
      "Traitement du département : 44\n",
      "Traitement du département : 50\n",
      "Traitement du département : 37\n",
      "Traitement du département : 81\n",
      "Traitement du département : 67\n",
      "Traitement du département : 93\n",
      "Traitement du département : 83\n",
      "Traitement du département : 63\n",
      "Traitement du département : 95\n",
      "Traitement du département : 76\n",
      "Traitement du département : 33\n",
      "Traitement du département : 78\n",
      "Traitement du département : 38\n",
      "Traitement du département : 51\n",
      "Traitement du département : 57\n",
      "Traitement du département : 77\n",
      "Traitement du département : 35\n",
      "Traitement du département : 54\n",
      "Traitement du département : 80\n",
      "Traitement du département : 36\n",
      "Traitement du département : 73\n",
      "Traitement du département : 31\n",
      "Traitement du département : 49\n",
      "Traitement du département : 60\n",
      "Traitement du département : 45\n",
      "Traitement du département : 14\n",
      "Traitement du département : 74\n",
      "Traitement du département : 41\n",
      "Traitement du département : 28\n",
      "Traitement du département : 10\n",
      "Traitement du département : 30\n",
      "Traitement du département : 58\n",
      "Traitement du département : 34\n",
      "Traitement du département : 12\n",
      "Traitement du département : 64\n",
      "Traitement du département : 55\n",
      "Traitement du département : 84\n",
      "Traitement du département : 24\n",
      "Traitement du département : 61\n",
      "Traitement du département : 27\n",
      "Traitement du département : 47\n",
      "Traitement du département : 89\n",
      "Traitement du département : 85\n",
      "Traitement du département : 87\n",
      "Traitement du département : 17\n",
      "Traitement du département : 06\n",
      "Traitement du département : 16\n",
      "Traitement du département : 07\n",
      "Traitement du département : 42\n",
      "Traitement du département : 72\n",
      "Traitement du département : 79\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 15\n",
      "Traitement du département : 25\n",
      "Traitement du département : 04\n",
      "Traitement du département : 23\n",
      "Traitement du département : 01\n",
      "Traitement du département : 66\n",
      "Traitement du département : 68\n",
      "Traitement du département : 53\n",
      "Traitement du département : 26\n",
      "Traitement du département : 05\n",
      "Traitement du département : 08\n",
      "Traitement du département : 18\n",
      "Traitement du département : 22\n",
      "Traitement du département : 40\n",
      "Traitement du département : 32\n",
      "Traitement du département : 88\n",
      "Traitement du département : 52\n",
      "Traitement du département : 43\n",
      "Traitement du département : 19\n",
      "Traitement du département : 71\n",
      "Traitement du département : 90\n",
      "Traitement du département : 86\n",
      "Traitement du département : 39\n",
      "Traitement du département : 65\n",
      "Traitement du département : 82\n",
      "Traitement du département : 09\n",
      "Traitement du département : 46\n",
      "Traitement du département : 48\n",
      "Traitement du département : 70\n",
      "Traitement du département : 972\n",
      "Traitement du département : 974\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 971\n",
      "Traitement du département : 976\n",
      "Traitement du département : 973\n",
      "Traitement du département : 988\n"
     ]
    }
   ],
   "source": [
    "def test_match3(vf, df):\n",
    "    merged = []\n",
    "\n",
    "\n",
    "    #boucle par département\n",
    "    for department in df['N°_département_(BAN)'].unique():  \n",
    "        print(f\"Traitement du département : {department}\")\n",
    "        \n",
    "        #filtre\n",
    "        vf_dept = vf[vf['Code postal'].astype(str).str.startswith(department)].copy()\n",
    "        df_dept = df[df['N°_département_(BAN)']==department].copy()\n",
    "\n",
    "        #normalisation adresses\n",
    "        vf_dept['Adresse'] = vf_dept['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "        vf_dept['Adresse_Normalisee'] = vf_dept.apply(lambda row: normalize_vf_address(row['Adresse'], row['Code postal']), axis=1)\n",
    "        df_dept['Adresse_Normalisee'] = df_dept['Adresse_(BAN)'].apply(normalize_address)\n",
    "\n",
    "        adresse_counts = vf_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique1 = list(adresse_counts[adresse_counts == 1].index)\n",
    "        doublons1 = list(adresse_counts[adresse_counts > 1].index)\n",
    "        final = unique1 + doublons1\n",
    "        set_final = set(final)\n",
    "\n",
    "        adresse_counts2 = df_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique2 = list(adresse_counts2[adresse_counts2 == 1].index)\n",
    "        doublons2 = list(adresse_counts2[adresse_counts2 > 1].index)\n",
    "        final2 = unique2 + doublons2\n",
    "        set_final2 = set(final2)\n",
    "\n",
    "        commun = set_final.intersection(set_final2)\n",
    "\n",
    "        vf_dept['Surface Carrez du 1er lot'] = pd.to_numeric(\n",
    "            vf_dept['Surface Carrez du 1er lot'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "        df_dept['Surface_habitable_logement'] = pd.to_numeric(\n",
    "            df_dept['Surface_habitable_logement'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "\n",
    "        for adresse in commun:\n",
    "            dfsub = df_dept[df_dept['Adresse_Normalisee'] == adresse]\n",
    "            vfsub = vf_dept[vf_dept['Adresse_Normalisee'] == adresse]\n",
    "\n",
    "            for _, row2 in dfsub.iterrows():\n",
    "                best_match = None\n",
    "                best_value = -1\n",
    "\n",
    "                for _, row1 in vfsub.iterrows():\n",
    "                    surface1 = row1['Surface Carrez du 1er lot']\n",
    "                    surface2 = row2['Surface_habitable_logement']\n",
    "\n",
    "                    #si surfaces identiques on match direct\n",
    "                    if surface1 == surface2:\n",
    "                        best_match = row1\n",
    "                        break\n",
    "\n",
    "                    #ecart inf à 10%\n",
    "                    if abs(surface1 - surface2) / max(surface1, surface2) < 0.1:\n",
    "                        valeur_fonciere = pd.to_numeric(str(row1.get('Valeur fonciere', 0)).replace(',', '.'), errors='coerce')\n",
    "                        if valeur_fonciere > best_value:\n",
    "                            best_value = valeur_fonciere\n",
    "                            best_match = row1\n",
    "\n",
    "                if best_match is not None:\n",
    "                    merged.append({**row2.to_dict(), **best_match.to_dict()})\n",
    "\n",
    "    #df des résultats fusionnés\n",
    "    df = pd.DataFrame(merged)\n",
    "    return df\n",
    "\n",
    "#application fonction\n",
    "test3 = test_match3(vf, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94314\n"
     ]
    }
   ],
   "source": [
    "print(len(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10 = test3.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88831\n"
     ]
    }
   ],
   "source": [
    "print(len(result10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10.to_csv(\"result10%.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST SEUIL DE 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 13\n",
      "Traitement du département : 92\n",
      "Traitement du département : 69\n",
      "Traitement du département : 03\n",
      "Traitement du département : 56\n",
      "Traitement du département : 75\n",
      "Traitement du département : 29\n",
      "Traitement du département : 91\n",
      "Traitement du département : 62\n",
      "Traitement du département : 21\n",
      "Traitement du département : 11\n",
      "Traitement du département : 02\n",
      "Traitement du département : 59\n",
      "Traitement du département : 94\n",
      "Traitement du département : 44\n",
      "Traitement du département : 50\n",
      "Traitement du département : 37\n",
      "Traitement du département : 81\n",
      "Traitement du département : 67\n",
      "Traitement du département : 93\n",
      "Traitement du département : 83\n",
      "Traitement du département : 63\n",
      "Traitement du département : 95\n",
      "Traitement du département : 76\n",
      "Traitement du département : 33\n",
      "Traitement du département : 78\n",
      "Traitement du département : 38\n",
      "Traitement du département : 51\n",
      "Traitement du département : 57\n",
      "Traitement du département : 77\n",
      "Traitement du département : 35\n",
      "Traitement du département : 54\n",
      "Traitement du département : 80\n",
      "Traitement du département : 36\n",
      "Traitement du département : 73\n",
      "Traitement du département : 31\n",
      "Traitement du département : 49\n",
      "Traitement du département : 60\n",
      "Traitement du département : 45\n",
      "Traitement du département : 14\n",
      "Traitement du département : 74\n",
      "Traitement du département : 41\n",
      "Traitement du département : 28\n",
      "Traitement du département : 10\n",
      "Traitement du département : 30\n",
      "Traitement du département : 58\n",
      "Traitement du département : 34\n",
      "Traitement du département : 12\n",
      "Traitement du département : 64\n",
      "Traitement du département : 55\n",
      "Traitement du département : 84\n",
      "Traitement du département : 24\n",
      "Traitement du département : 61\n",
      "Traitement du département : 27\n",
      "Traitement du département : 47\n",
      "Traitement du département : 89\n",
      "Traitement du département : 85\n",
      "Traitement du département : 87\n",
      "Traitement du département : 17\n",
      "Traitement du département : 06\n",
      "Traitement du département : 16\n",
      "Traitement du département : 07\n",
      "Traitement du département : 42\n",
      "Traitement du département : 72\n",
      "Traitement du département : 79\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 15\n",
      "Traitement du département : 25\n",
      "Traitement du département : 04\n",
      "Traitement du département : 23\n",
      "Traitement du département : 01\n",
      "Traitement du département : 66\n",
      "Traitement du département : 68\n",
      "Traitement du département : 53\n",
      "Traitement du département : 26\n",
      "Traitement du département : 05\n",
      "Traitement du département : 08\n",
      "Traitement du département : 18\n",
      "Traitement du département : 22\n",
      "Traitement du département : 40\n",
      "Traitement du département : 32\n",
      "Traitement du département : 88\n",
      "Traitement du département : 52\n",
      "Traitement du département : 43\n",
      "Traitement du département : 19\n",
      "Traitement du département : 71\n",
      "Traitement du département : 90\n",
      "Traitement du département : 86\n",
      "Traitement du département : 39\n",
      "Traitement du département : 65\n",
      "Traitement du département : 82\n",
      "Traitement du département : 09\n",
      "Traitement du département : 46\n",
      "Traitement du département : 48\n",
      "Traitement du département : 70\n",
      "Traitement du département : 972\n",
      "Traitement du département : 974\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 971\n",
      "Traitement du département : 976\n",
      "Traitement du département : 973\n",
      "Traitement du département : 988\n"
     ]
    }
   ],
   "source": [
    "def test_match4(vf, df):\n",
    "    merged = []\n",
    "\n",
    "\n",
    "    #boucle par département\n",
    "    for department in df['N°_département_(BAN)'].unique():  \n",
    "        print(f\"Traitement du département : {department}\")\n",
    "        \n",
    "        #filtre\n",
    "        vf_dept = vf[vf['Code postal'].astype(str).str.startswith(department)].copy()\n",
    "        df_dept = df[df['N°_département_(BAN)']==department].copy()\n",
    "\n",
    "        #normalisation adresses\n",
    "        vf_dept['Adresse'] = vf_dept['Adresse'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "        vf_dept['Adresse_Normalisee'] = vf_dept.apply(lambda row: normalize_vf_address(row['Adresse'], row['Code postal']), axis=1)\n",
    "        df_dept['Adresse_Normalisee'] = df_dept['Adresse_(BAN)'].apply(normalize_address)\n",
    "\n",
    "        adresse_counts = vf_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique1 = list(adresse_counts[adresse_counts == 1].index)\n",
    "        doublons1 = list(adresse_counts[adresse_counts > 1].index)\n",
    "        final = unique1 + doublons1\n",
    "        set_final = set(final)\n",
    "\n",
    "        adresse_counts2 = df_dept['Adresse_Normalisee'].dropna().value_counts()\n",
    "        unique2 = list(adresse_counts2[adresse_counts2 == 1].index)\n",
    "        doublons2 = list(adresse_counts2[adresse_counts2 > 1].index)\n",
    "        final2 = unique2 + doublons2\n",
    "        set_final2 = set(final2)\n",
    "\n",
    "        commun = set_final.intersection(set_final2)\n",
    "\n",
    "        vf_dept['Surface Carrez du 1er lot'] = pd.to_numeric(\n",
    "            vf_dept['Surface Carrez du 1er lot'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "        df_dept['Surface_habitable_logement'] = pd.to_numeric(\n",
    "            df_dept['Surface_habitable_logement'].astype(str).str.replace(',', '.'), errors='coerce'\n",
    "        )\n",
    "\n",
    "        for adresse in commun:\n",
    "            dfsub = df_dept[df_dept['Adresse_Normalisee'] == adresse]\n",
    "            vfsub = vf_dept[vf_dept['Adresse_Normalisee'] == adresse]\n",
    "\n",
    "            for _, row2 in dfsub.iterrows():\n",
    "                best_match = None\n",
    "                best_value = -1\n",
    "\n",
    "                for _, row1 in vfsub.iterrows():\n",
    "                    surface1 = row1['Surface Carrez du 1er lot']\n",
    "                    surface2 = row2['Surface_habitable_logement']\n",
    "\n",
    "                    #si surfaces identiques on match direct\n",
    "                    if surface1 == surface2:\n",
    "                        best_match = row1\n",
    "                        break\n",
    "\n",
    "                    #ecart inf à 3%\n",
    "                    if abs(surface1 - surface2) / max(surface1, surface2) < 0.03:\n",
    "                        valeur_fonciere = pd.to_numeric(str(row1.get('Valeur fonciere', 0)).replace(',', '.'), errors='coerce')\n",
    "                        if valeur_fonciere > best_value:\n",
    "                            best_value = valeur_fonciere\n",
    "                            best_match = row1\n",
    "\n",
    "                if best_match is not None:\n",
    "                    merged.append({**row2.to_dict(), **best_match.to_dict()})\n",
    "\n",
    "    #df des résultats fusionnés\n",
    "    df = pd.DataFrame(merged)\n",
    "    return df\n",
    "\n",
    "#application fonction\n",
    "test4 = test_match4(vf, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73502\n"
     ]
    }
   ],
   "source": [
    "print(len(test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = test4.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69313\n"
     ]
    }
   ],
   "source": [
    "print(len(result3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3.to_csv(\"result3%.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST AUTRES ANNEES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble que nous ne disposions que des données à partir de 2021, nous pouvons tout de même vérifier que c'est bien le cas car les fichiers valeurs foncières s'étendent jusqu'à 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_réception_DPE'] = pd.to_datetime(df['Date_réception_DPE'], errors='coerce')\n",
    "df2014 = df[df['Date_réception_DPE'].dt.year == 2014].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df2014))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2015 = df[df['Date_réception_DPE'].dt.year == 2015].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2016 = df[df['Date_réception_DPE'].dt.year == 2016].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017 = df[df['Date_réception_DPE'].dt.year == 2017].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018 = df[df['Date_réception_DPE'].dt.year == 2018].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2019 = df[df['Date_réception_DPE'].dt.year == 2019].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020 = df[df['Date_réception_DPE'].dt.year == 2020].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(df2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021 = df[df['Date_réception_DPE'].dt.year == 2021].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677703\n"
     ]
    }
   ],
   "source": [
    "print(len(df2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2023= df[df['Date_réception_DPE'].dt.year == 2023].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438813\n"
     ]
    }
   ],
   "source": [
    "print(len(df2023))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons donc pouvoir seulement compiler les données pour les années : 2021, 2022,2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSE DES DONNEES COMMUNES ENTRE DF ET DF2 (LOGEMENTS EXISTANTS ET NEUFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes communes : ['Version_DPE', 'Code_postal_(BAN)', 'Code_INSEE_(BAN)', 'Date_fin_validité_DPE', 'Identifiant__BAN', 'N°_région_(BAN)', 'Date_réception_DPE', 'Nom_résidence', \"Complément_d'adresse_bâtiment\", \"Cage_d'escalier\", 'Date_établissement_DPE', 'Nom__commune_(Brut)', 'N°_voie_(BAN)', 'Etiquette_DPE', 'N°_département_(BAN)', 'Adresse_brute', 'Nom__commune_(BAN)', 'Score_BAN', 'Code_postal_(brut)', 'Adresse_(BAN)', 'Etiquette_GES', 'Nom__rue_(BAN)', 'Coordonnée_cartographique_X_(BAN)', 'Modèle_DPE', 'Statut_géocodage', 'Type_bâtiment', 'Coordonnée_cartographique_Y_(BAN)', 'Adresse_Normalisee', 'Surface_habitable_logement', \"Complément_d'adresse_logement\", 'N°_étage_appartement']\n",
      "\n",
      "Lignes en doublons pour les colonnes communes :\n",
      "Empty DataFrame\n",
      "Columns: [Version_DPE, Code_postal_(BAN), Code_INSEE_(BAN), Date_fin_validité_DPE, Identifiant__BAN, N°_région_(BAN), Date_réception_DPE, Nom_résidence, Complément_d'adresse_bâtiment, Cage_d'escalier, Date_établissement_DPE, Nom__commune_(Brut), N°_voie_(BAN), Etiquette_DPE, N°_département_(BAN), Adresse_brute, Nom__commune_(BAN), Score_BAN, Code_postal_(brut), Adresse_(BAN), Etiquette_GES, Nom__rue_(BAN), Coordonnée_cartographique_X_(BAN), Modèle_DPE, Statut_géocodage, Type_bâtiment, Coordonnée_cartographique_Y_(BAN), Adresse_Normalisee, Surface_habitable_logement, Complément_d'adresse_logement, N°_étage_appartement]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "def trouver_doublons_colonnes_communes(df, df2):\n",
    "    #colonnes communes\n",
    "    colonnes_communes = list(set(df.columns).intersection(df2.columns))\n",
    "    print(f\"Colonnes communes : {colonnes_communes}\")\n",
    "    \n",
    "    #doublons parmi colonnes communes\n",
    "    doublons = pd.merge(df[colonnes_communes], df2[colonnes_communes], how='inner')\n",
    "    return doublons\n",
    "\n",
    "doublons = trouver_doublons_colonnes_communes(df, df2)\n",
    "\n",
    "print(\"\\nLignes en doublons pour les colonnes communes :\")\n",
    "print(doublons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a pas de doublons entre df et df2 donc on peut merge les deux séparément avec vf puis les compiler. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge de df2 avec vf pour 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Date_réception_DPE'] = pd.to_datetime(df2['Date_réception_DPE'], errors='coerce')\n",
    "df2 = df2[df2['Date_réception_DPE'].dt.year == 2022].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = vf[vf['Code postal'].notna()]\n",
    "df2 = df2[df2['N°_département_(BAN)'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf['Code postal'] = vf['Code postal'].astype(int).astype(str)\n",
    "df2.loc[:, 'N°_département_(BAN)'] = df2['N°_département_(BAN)'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 29\n",
      "Traitement du département : 69\n",
      "Traitement du département : 33\n",
      "Traitement du département : 83\n",
      "Traitement du département : 31\n",
      "Traitement du département : 13\n",
      "Traitement du département : 93\n",
      "Traitement du département : 92\n",
      "Traitement du département : 14\n",
      "Traitement du département : 81\n",
      "Traitement du département : 07\n",
      "Traitement du département : 30\n",
      "Traitement du département : 84\n",
      "Traitement du département : 85\n",
      "Traitement du département : 34\n",
      "Traitement du département : 63\n",
      "Traitement du département : 77\n",
      "Traitement du département : 66\n",
      "Traitement du département : 51\n",
      "Traitement du département : 57\n",
      "Traitement du département : 44\n",
      "Traitement du département : 91\n",
      "Traitement du département : 47\n",
      "Traitement du département : 64\n",
      "Traitement du département : 87\n",
      "Traitement du département : 88\n",
      "Traitement du département : 50\n",
      "Traitement du département : 38\n",
      "Traitement du département : 72\n",
      "Traitement du département : 74\n",
      "Traitement du département : 79\n",
      "Traitement du département : 35\n",
      "Traitement du département : 49\n",
      "Traitement du département : 82\n",
      "Traitement du département : 11\n",
      "Traitement du département : 40\n",
      "Traitement du département : 58\n",
      "Traitement du département : 59\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 22\n",
      "Traitement du département : 68\n",
      "Traitement du département : 62\n",
      "Traitement du département : 95\n",
      "Traitement du département : 60\n",
      "Traitement du département : 06\n",
      "Traitement du département : 78\n",
      "Traitement du département : 21\n",
      "Traitement du département : 86\n",
      "Traitement du département : 24\n",
      "Traitement du département : 19\n",
      "Traitement du département : 67\n",
      "Traitement du département : 17\n",
      "Traitement du département : 36\n",
      "Traitement du département : 972\n",
      "Traitement du département : 76\n",
      "Traitement du département : 26\n",
      "Traitement du département : 56\n",
      "Traitement du département : 27\n",
      "Traitement du département : 42\n",
      "Traitement du département : 10\n",
      "Traitement du département : 25\n",
      "Traitement du département : 54\n",
      "Traitement du département : 89\n",
      "Traitement du département : 80\n",
      "Traitement du département : 01\n",
      "Traitement du département : 37\n",
      "Traitement du département : 94\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 04\n",
      "Traitement du département : 12\n",
      "Traitement du département : 43\n",
      "Traitement du département : 45\n",
      "Traitement du département : 41\n",
      "Traitement du département : 16\n",
      "Traitement du département : 46\n",
      "Traitement du département : 18\n",
      "Traitement du département : 05\n",
      "Traitement du département : 75\n",
      "Traitement du département : 28\n",
      "Traitement du département : 73\n",
      "Traitement du département : 32\n",
      "Traitement du département : 09\n",
      "Traitement du département : 55\n",
      "Traitement du département : 71\n",
      "Traitement du département : 15\n",
      "Traitement du département : 65\n",
      "Traitement du département : 39\n",
      "Traitement du département : 48\n",
      "Traitement du département : 02\n",
      "Traitement du département : 974\n",
      "Traitement du département : 03\n",
      "Traitement du département : 90\n",
      "Traitement du département : 70\n",
      "Traitement du département : 53\n",
      "Traitement du département : 23\n",
      "Traitement du département : 08\n",
      "Traitement du département : 61\n",
      "Traitement du département : 52\n",
      "Traitement du département : 971\n",
      "Traitement du département : 976\n",
      "Traitement du département : 973\n"
     ]
    }
   ],
   "source": [
    "dfneuf5 = test_match2(vf, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2714\n"
     ]
    }
   ],
   "source": [
    "print(len(dfneuf5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneuf5 = dfneuf5.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1911\n"
     ]
    }
   ],
   "source": [
    "print(len(dfneuf5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/ymcp1z4s7n77n5bhz3q_hgqc0000gn/T/ipykernel_1037/4222365088.py:1: DtypeWarning: Columns (15,58,60,62,65,67,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfexistant5 = pd.read_csv(\"result5%.csv\")\n"
     ]
    }
   ],
   "source": [
    "dfexistant5 = pd.read_csv(\"result5%.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation des deux "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler les deux DataFrames\n",
    "def compiler_dataframes(df1, df2):\n",
    "    #concatène les deux DataFrames\n",
    "    df_compilé = pd.concat([df1, df2], ignore_index=True)\n",
    "    #supprime doublons\n",
    "    df_compilé = df_compilé.drop_duplicates()\n",
    "    return df_compilé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compilé = compiler_dataframes(dfexistant5, dfneuf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compilé.to_csv(\"result5%_2022_compilé.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79059\n"
     ]
    }
   ],
   "source": [
    "print(len(df_compilé))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf2021 = pd.read_csv(\n",
    "    \"/Users/noelinecasteil/Documents/statapp/ValeursFoncieres/valeursfoncieres-2021.txt\",\n",
    "    sep=\"|\",  \n",
    "    encoding=\"utf-8\",\n",
    "    low_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir explicitement toutes les colonnes en chaînes\n",
    "vf2021['Adresse'] = vf2021['No voie'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf2021['Type de voie'].fillna('').astype(str) + \" \" + \\\n",
    "                vf2021['Voie'].fillna('').astype(str) + \", \" + \\\n",
    "                vf2021['Code postal'].apply(lambda x: str(int(x)) if pd.notna(x) else '').astype(str) + \" \" + \\\n",
    "                vf2021['Commune'].fillna('').astype(str)\n",
    "\n",
    "vf2021['Adresse'] = vf2021['Adresse'].str.strip().replace(r'^\\s*$', None, regex=True)  # Supprime les adresses vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_réception_DPE'] = pd.to_datetime(df['Date_réception_DPE'], errors='coerce')\n",
    "df2021 = df[df['Date_réception_DPE'].dt.year == 2021].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf2021 = vf2021[vf2021['Code postal'].notna()]\n",
    "df2021 = df2021[df2021['N°_département_(BAN)'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf2021['Code postal'] = vf2021['Code postal'].astype(int).astype(str)\n",
    "df2021.loc[:, 'N°_département_(BAN)'] = df2021['N°_département_(BAN)'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MATCHING 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 25\n",
      "Traitement du département : 44\n",
      "Traitement du département : 36\n",
      "Traitement du département : 29\n",
      "Traitement du département : 43\n",
      "Traitement du département : 06\n",
      "Traitement du département : 88\n",
      "Traitement du département : 78\n",
      "Traitement du département : 14\n",
      "Traitement du département : 80\n",
      "Traitement du département : 54\n",
      "Traitement du département : 82\n",
      "Traitement du département : 49\n",
      "Traitement du département : 86\n",
      "Traitement du département : 52\n",
      "Traitement du département : 64\n",
      "Traitement du département : 59\n",
      "Traitement du département : 77\n",
      "Traitement du département : 72\n",
      "Traitement du département : 67\n",
      "Traitement du département : 60\n",
      "Traitement du département : 89\n",
      "Traitement du département : 41\n",
      "Traitement du département : 30\n",
      "Traitement du département : 69\n",
      "Traitement du département : 81\n",
      "Traitement du département : 85\n",
      "Traitement du département : 57\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 76\n",
      "Traitement du département : 35\n",
      "Traitement du département : 56\n",
      "Traitement du département : 40\n",
      "Traitement du département : 27\n",
      "Traitement du département : 68\n",
      "Traitement du département : 47\n",
      "Traitement du département : 79\n",
      "Traitement du département : 73\n",
      "Traitement du département : 62\n",
      "Traitement du département : 58\n",
      "Traitement du département : 22\n",
      "Traitement du département : 08\n",
      "Traitement du département : 63\n",
      "Traitement du département : 42\n",
      "Traitement du département : 74\n",
      "Traitement du département : 38\n",
      "Traitement du département : 65\n",
      "Traitement du département : 84\n",
      "Traitement du département : 26\n",
      "Traitement du département : 31\n",
      "Traitement du département : 83\n",
      "Traitement du département : 46\n",
      "Traitement du département : 24\n",
      "Traitement du département : 28\n",
      "Traitement du département : 11\n",
      "Traitement du département : 92\n",
      "Traitement du département : 87\n",
      "Traitement du département : 13\n",
      "Traitement du département : 51\n",
      "Traitement du département : 50\n",
      "Traitement du département : 75\n",
      "Traitement du département : 04\n",
      "Traitement du département : 91\n",
      "Traitement du département : 01\n",
      "Traitement du département : 71\n",
      "Traitement du département : 05\n",
      "Traitement du département : 21\n",
      "Traitement du département : 45\n",
      "Traitement du département : 93\n",
      "Traitement du département : 32\n",
      "Traitement du département : 61\n",
      "Traitement du département : 17\n",
      "Traitement du département : 55\n",
      "Traitement du département : 95\n",
      "Traitement du département : 33\n",
      "Traitement du département : 39\n",
      "Traitement du département : 19\n",
      "Traitement du département : 37\n",
      "Traitement du département : 53\n",
      "Traitement du département : 70\n",
      "Traitement du département : 94\n",
      "Traitement du département : 90\n",
      "Traitement du département : 66\n",
      "Traitement du département : 34\n",
      "Traitement du département : 16\n",
      "Traitement du département : 03\n",
      "Traitement du département : 18\n",
      "Traitement du département : 02\n",
      "Traitement du département : 07\n",
      "Traitement du département : 15\n",
      "Traitement du département : 09\n",
      "Traitement du département : 12\n",
      "Traitement du département : 23\n",
      "Traitement du département : 10\n",
      "Traitement du département : 972\n",
      "Traitement du département : 48\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 974\n",
      "Traitement du département : 973\n",
      "Traitement du département : 976\n",
      "Traitement du département : 971\n"
     ]
    }
   ],
   "source": [
    "dfexistant2021 = test_match2(vf2021, df2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexistant2021 = dfexistant2021.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21335\n"
     ]
    }
   ],
   "source": [
    "print(len(dfexistant2021))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGEMENTS NEUFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Date_réception_DPE'] = pd.to_datetime(df2['Date_réception_DPE'], errors='coerce')\n",
    "df22021 = df2[df2['Date_réception_DPE'].dt.year == 2021].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22021 = df22021[df22021['N°_département_(BAN)'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22021.loc[:, 'N°_département_(BAN)'] = df22021['N°_département_(BAN)'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF NEUF à 5% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du département : 33\n",
      "Traitement du département : 91\n",
      "Traitement du département : 64\n",
      "Traitement du département : 57\n",
      "Traitement du département : 63\n",
      "Traitement du département : 80\n",
      "Traitement du département : 74\n",
      "Traitement du département : 95\n",
      "Traitement du département : 26\n",
      "Traitement du département : 37\n",
      "Traitement du département : 77\n",
      "Traitement du département : 76\n",
      "Traitement du département : 38\n",
      "Traitement du département : 35\n",
      "Traitement du département : 92\n",
      "Traitement du département : 56\n",
      "Traitement du département : 31\n",
      "Traitement du département : 94\n",
      "Traitement du département : 89\n",
      "Traitement du département : 69\n",
      "Traitement du département : 01\n",
      "Traitement du département : 42\n",
      "Traitement du département : 44\n",
      "Traitement du département : 93\n",
      "Traitement du département : 21\n",
      "Traitement du département : 45\n",
      "Traitement du département : 17\n",
      "Traitement du département : 68\n",
      "Traitement du département : 58\n",
      "Traitement du département : 73\n",
      "Traitement du département : 13\n",
      "Traitement du département : 14\n",
      "Traitement du département : 62\n",
      "Traitement du département : 15\n",
      "Traitement du département : 61\n",
      "Traitement du département : 34\n",
      "Traitement du département : 59\n",
      "Traitement du département : 67\n",
      "Traitement du département : 49\n",
      "Traitement du département : 78\n",
      "Traitement du département : 40\n",
      "Traitement du département : 60\n",
      "Traitement du département : 51\n",
      "Traitement du département : 29\n",
      "Traitement du département : 85\n",
      "Traitement du département : 16\n",
      "Traitement du département : 03\n",
      "Traitement du département : 06\n",
      "Traitement du département : 10\n",
      "Traitement du département : 47\n",
      "Traitement du département : 25\n",
      "Traitement du département : 75\n",
      "Traitement du département : 05\n",
      "Traitement du département : 30\n",
      "Traitement du département : 87\n",
      "Traitement du département : 81\n",
      "Traitement du département : 83\n",
      "Traitement du département : 2A\n",
      "Traitement du département : 24\n",
      "Traitement du département : 22\n",
      "Traitement du département : 18\n",
      "Traitement du département : 54\n",
      "Traitement du département : 27\n",
      "Traitement du département : 84\n",
      "Traitement du département : 50\n",
      "Traitement du département : 32\n",
      "Traitement du département : 39\n",
      "Traitement du département : 28\n",
      "Traitement du département : 19\n",
      "Traitement du département : 53\n",
      "Traitement du département : 07\n",
      "Traitement du département : 90\n",
      "Traitement du département : 70\n",
      "Traitement du département : 36\n",
      "Traitement du département : 43\n",
      "Traitement du département : 12\n",
      "Traitement du département : 02\n",
      "Traitement du département : 79\n",
      "Traitement du département : 41\n",
      "Traitement du département : 972\n",
      "Traitement du département : 72\n",
      "Traitement du département : 65\n",
      "Traitement du département : 71\n",
      "Traitement du département : 04\n",
      "Traitement du département : 09\n",
      "Traitement du département : 86\n",
      "Traitement du département : 66\n",
      "Traitement du département : 08\n",
      "Traitement du département : 11\n",
      "Traitement du département : 2B\n",
      "Traitement du département : 82\n",
      "Traitement du département : 46\n",
      "Traitement du département : 88\n",
      "Traitement du département : 48\n",
      "Traitement du département : 55\n",
      "Traitement du département : 974\n",
      "Traitement du département : 52\n",
      "Traitement du département : 971\n",
      "Traitement du département : 23\n"
     ]
    }
   ],
   "source": [
    "dfneuf2021 = test_match2(vf2021, df22021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfneuf2021 = dfneuf2021.drop_duplicates(subset=['Date_réception_DPE', 'Adresse_Normalisee', 'Surface_habitable_logement', 'Valeur fonciere', 'N°_étage_appartement', 'Etiquette_DPE', \"Complément_d'adresse_logement\", \"Complément_d'adresse_bâtiment\", \"Date_établissement_DPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676\n"
     ]
    }
   ],
   "source": [
    "print(len(dfneuf2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021compile = compiler_dataframes(dfexistant2021, dfneuf2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021compile.to_csv(\"result5%_2021_compilé.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On n'a pas les valeurs foncières de 2023 mince"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA FRAME FINAL POUR 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bf/ymcp1z4s7n77n5bhz3q_hgqc0000gn/T/ipykernel_1037/1554524822.py:1: DtypeWarning: Columns (58,60,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(\"result5%_2021_compilé.csv\")\n",
      "/var/folders/bf/ymcp1z4s7n77n5bhz3q_hgqc0000gn/T/ipykernel_1037/1554524822.py:2: DtypeWarning: Columns (15,58,60,62,65,67,75) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(\"result5%_2022_compilé.csv\")\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"result5%_2021_compilé.csv\")\n",
    "df2 = pd.read_csv(\"result5%_2022_compilé.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffinal5 = compiler_dataframes(df1, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffinal5.to_csv(\"dataframefinal_5%.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
